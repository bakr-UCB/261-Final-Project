{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07200125-b718-42cd-9e79-0216d6a259d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# PHASE II RUBRIC\n",
    "\n",
    "#### 1. In class presentation\n",
    "- In-class explanation, and discussion  of your results (as part of the final exam period)\n",
    "\n",
    "#### 2. Team and project meta information.\n",
    "\n",
    "- Highlight the Phase leader who is the contact person for this phase.\n",
    "\n",
    "#### 3. Updated Credit assignment plan\n",
    "- Credit assignment plan updates (who does/did what and when) in Table format\n",
    "- No Credit assignment plan means ZERO points\n",
    "- Credit assignment plan not in Table format means ZERO points\n",
    "- No start and end dates and budgeted hours of effort means an incomplete plan. May result in zero points.\n",
    "\n",
    "#### 4. Project Abstract\n",
    "- Abstract:\n",
    "- You now have some results! So your abstract should be an evolved version of your Phase 1's abstract (plus any feedback that you got!). For Phase 2:\n",
    "- 1.- Repeat the same components of Phase 1: Business problem, data used and sources, etc.\n",
    "- 2.- Explain your baseline: why did you select it and what's the results of your metric in the baseline.\n",
    "- 3.- What are the most important Features that you are using/planning to use.\n",
    "- 4.- Next steps.\n",
    "- Always be concise. This abstract should have between 2 or 3 paragraphs top.\n",
    "\n",
    "#### 5. Project Description (data and tasks)\n",
    "- Description of the data and task at hand\n",
    "- --Data description\n",
    "- --Task to be tackled\n",
    "- -- Provide diagrams to aid understanding the workflow\n",
    "\n",
    "#### 6. EDA\n",
    "- -- Summary description of each table in English.\n",
    "- -- A data dictionary of the raw features (test description; data type: numerical, list, etc.)\n",
    "- -- Dataset size (rows columns, train, test, validation)\n",
    "- -- Summary statistics\n",
    "- -- Correlation analysis\n",
    "- -- Other useful text-based analysis (as opposed to graphic-based)\n",
    "- Here are some ideas of what it should have, you DON'T NEED to do all of them!\n",
    "- -- A visualization of each of the input and target features (looking at the distribution, and the central tendencies as captured by the mean, median etc.)\n",
    "- -- A visualization of the correlation analysis\n",
    "- -- pair-based visualization of the input and output features\n",
    "- Overall, make sure your graphics are: well sized, readable; have titles, have xlabels with units, have ylabels with units; bonus points for graphics with annotations!\n",
    "- -- a graphic summary of the missing value analysis\n",
    "- -- other novel visualizations (e.g., geo-plot)\n",
    "\n",
    "\n",
    "#### 7. Modeling Pipelines\n",
    "- -- A visualization of the modeling pipeline (s) and sub pipelines if necessary\n",
    "- -- Families of input features and count per family\n",
    "- -- Number of input features\n",
    "- -- Loss function used (data loss and regularization parts) in latex\n",
    "- -- Number of experiments conducted\n",
    "- -- Describe cluster size, and how many minutes it takes to build each model type.\n",
    "- -- Experiment table with the following details per experiment:\n",
    "- ----- Baseline experiment\n",
    "- ---- The families of input features used\n",
    "- ----- For train/valid/test record the following in a Pandas DataFrame:\n",
    "- ---- List Metrics used along with: their Latex equations\n",
    "\n",
    "#### 8. Results and discussion of results\n",
    "\n",
    "- Please report the results of training (first three-quarters of the one-year dataset), and blind testing (the last quarter of the available one-year dataset).\n",
    "- The aim of the discussion section is to review experiments conducted and draw conclusions about key pipelines (supported by experimental results).. **Often, this part is the most important, simply because it lets the researcher take a step back and give a broader look at the experiment.** Do not discuss any outcomes not presented in the results part (not supported by experiments).\n",
    "\n",
    "#### 9. Conclusion\n",
    "- Expectations here are to address the following following in your conclusion (in about 150 words) in a main section by itself:\n",
    "- -- Restate your project focus explain why it’s important. Make sure that this part of the conclusion is concise and clear.\n",
    "- -- Restate your hypothesis (e.g., ML pipelines with custom features can accurately forecast .....)\n",
    "- -- Summarize the main points of your project: Remind your readers of your key contributions.\n",
    "- -- Discuss the significance of your results\n",
    "- -- Discuss the future of your project and closing thoughts.\n",
    "\n",
    "\n",
    "#### 10.Joining the data [Extra Credit]\n",
    "- -- steps in your joins in words, code, and data sizes for all the data\n",
    "- -- Joins need to be reported and performed on all the data (not just 3/6/12 months).\n",
    "- -- join statistics (table sizes, time to run joins, and cluster sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ecd627d-9ebc-4fd0-ae5b-20c814e9d29c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Phase II Project Report\n",
    "__`Team 4-1`__\n",
    "\n",
    "## Phase II lead by Shruti Gupta\n",
    "## Authored By:\n",
    "\n",
    "<div style=\"text-align: center; line-height: 10; padding-top: 30px;  padding-bottom: 30px;\">\n",
    "<img src=\"https://github.com/bakr-UCB/261-Final-Project/blob/main/authors.png?raw=true\" alt=\"ML Pipeline\" style=\"width: 500px\">\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe783fdb-2d27-4045-b4c7-935de8895f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Phase Leader Plan\n",
    "| Phase |  Phase Leader |\n",
    "|:---:|:---:|\n",
    "| **Phase 0, HW5**: Finalize Teams, and submitting HW5 | Danielle Yoseloff |\n",
    "| **Phase 1**: Project Plan, describe datasets, joins, tasks, and metrics  | Mohamed Bakr |\n",
    "|**Phase 2**: EDA, baseline pipeline, Scalability, Efficiency, Distributed/parallel Training, and Scoring Pipeline| Shruti Gupta |\n",
    "|**Phase 3**: Select the optimal algorithm, fine-tune and submit a final report| Erica Landreth |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59c46d31-94ed-4a47-ad6a-e38db513c7d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "## Credit assignment plan \n",
    "\n",
    "| Phase | team Meamber | Tasks | Hrs|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|**PHASE 0**| Danielle Yoseloff | Forming Team, Create Slack Channel, and team introduction |  2 |\n",
    "|**PHASE 1**| Danielle Yoseloff | Machine algorithms and metrics | 8 |\n",
    "|| | Pipeline Graph | 1 |\n",
    "||Erica Landreth | Abstract and Report Editing | 3 |\n",
    "||| EDA | 2.5 |\n",
    "||| Data Description | 8 |\n",
    "|| Shruti Gupta | EDA | 4 |\n",
    "|| |Missing & Null Value Exploration | 4 |\n",
    "|| Mohamed Bakr | Phase Leader Table, Credit Assigment plan, and GANTT chart |  8 |\n",
    "||| Digesting the Data and Checkpointing Strategy | 4 |\n",
    "|||Report editing and review| 2 |\n",
    "|**PHASE 2**| Danielle Yoseloff | | |\n",
    "||Erica Landreth | EDA and Cleaning | 11.5 |\n",
    "||| Pipeline and Cross Validation Development | 6.5 |\n",
    "||| Feature Engineering | 9.5 |\n",
    "||| Slides and Report | 8 |\n",
    "|| Shruti Gupta | | |\n",
    "|| Mohamed Bakr | | |\n",
    "|**PHASE 3**| Danielle Yoseloff | | |\n",
    "||Erica Landreth | | |\n",
    "|| Shruti Gupta | | |\n",
    "|| Mohamed Bakr | | |\n",
    "\n",
    "\n",
    "**Detailed Plan and GANTT Chart:** https://docs.google.com/spreadsheets/d/1E4A3SaTAEjh9owH4SBUMv987bktwrW4Q6TXCZ5LJ6Xg/edit?usp=sharing\n",
    "\n",
    "**Note:** Phase 3 plans are tentative and subject to change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c7073d3-5834-4919-9e96-2f2622131033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####4.  _Abstract Rubric_ \n",
    "1. Repeat the same components of Phase 1: Business problem, data used and sources, etc.\n",
    "2. Explain your baseline: why did you select it and what's the results of your metric in the baseline.\n",
    "3. What are the most important Features that you are using/planning to use.\n",
    "4. Next steps.\n",
    "- Always be concise. This abstract should have between 2 or 3 paragraphs top.\n",
    "\n",
    "#### _Phase I Abstract Feedback_ \n",
    "Good first try of the abstract. Good that you added sources of the data, very good practice! Now, predictive model is too broad, be very specific about what exactly are you predicting and why. I'm not convinced that F-1 is the right metric by reading your abstract, given that you didn't monetize why do we want a balance between precision and recall. Your metric has to have business impact and the abstract needs to be clear about it. The first paragraph has too much fluff, I want to know as a reader why should I care about your project in a business sense. Good job at clarifying what is your baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ee4d207-94a3-411e-8def-a3a5bbf2753d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Abstract \n",
    "\n",
    "According to a 2019 FAA study, national airline delay-related costs exceeded $8 billion due to increased operating expenses. [(2)](https://www.sciencedirect.com/science/article/pii/S019126152300142X#b1) Equipping airports with predictive systems for flight disruptions enables proactive mitigation strategies to absorb operational shocks and prevent cascading delays throughout the system. Therefore, our team aims to design a machine learning model to predict whether a flight will be disrupted (defined as delayed or cancelled) versus on schedule two hours before its scheduled departure. We will rely on historic Department of Transportation (DoT) flight data and associated National Oceanic and Atmospheric Association (NOAA) weather station reports from the years 2015 to 2021. All results discussed in this report are with respect to a 1-year subset of data selected from the full dataset ranging over 2019.\n",
    "\n",
    "Logistic regression was chosen for a baseline model because of its suitability for a binary outcome, interpretability, and strong performance on linearly separable data. F2 score will be used to evaluate model performance, reflecting the airports' priority to penalize false negatives (i.e., incorrectly predicting disrupted flights as on schedule). Initial results presented are based on airport, flight, and weather features at the airport of origin observed at least 2 hours before scheduled departure time, as well as daily and weekly seasonality components extracted from a Prophet model trained on the 1-year subset. The baseline model achieved an F2 score of .4631 on the training set and .4858 on the test set. To improve these results, we focused on estimating recency-based features to track arriving aircrafts given 2-hour stale information, which resulted in an F2 of .5895 on train and .5732 on test. This score indicates [**FILL IN**]. Our key features included weather and airport characteristics observed at the flight origin airport and estimated travel time characteristics of the prior flight.\n",
    " \n",
    "Moving forward to handle the full 5-year dataset, we we will pursue more advanced architectures (random forest, XGBoost, multi-layer-perceptron neural networks, and grpah-based neural networks). We will also engineer graph features to more effectively capture the anticipated effect of delay propagation and introduce yearly seasonality components from a Prophet model trained on the full dataset.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3ff498d-7d0b-4e23-a67b-6ba3de4d210f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### _5. Project Description (data and tasks) Rubric_\n",
    "- Description of the data and task at hand\n",
    "- --Data description\n",
    "- --Task to be tackled\n",
    "- -- Provide diagrams to aid understanding the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ede1c0d-31a9-4bc0-84c2-41676b907e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Research Objective\n",
    "\n",
    "Our primary customer is the airport management and administration. Based on our business case, we use the FAA definition of delay, which applies to a flight that departs 15 minutes or more after its scheduled departure; we assume that 15 minutes of delay defines the cutoff after which airport resources may need to be reallocated. We may also consider cancelled flights to be delayed based on our business scenario. Our objective is to use machine learning classification models to predict departure delay status based on flight,airport, and weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8464e894-cb38-428f-b921-ee70dfdcba75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebb49b27-c36c-4b45-8d6d-c06f513e6dca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data size and source\n",
    "\n",
    "| Dataset Name     | Dataset Size    | Dataset Description      |Dataset Source   |\n",
    "| :-------------: | ------------- | ------------- |  ------------- |\n",
    "| Flights | 2019 1 year data: 14,844,074 rows by 109 columns | DoT historical flight data from the years 2015-2021 | [4] |\n",
    "| Weather | 2019 1 year data: 59,270,147 rows by 130 columns | NOAA weather conditions for the corresponding time period | [2], [3] |\n",
    "| Stations | 5,004,169 rows by 12 columns | The weather station data defines the distances from various weather stations to various airports. |  |\n",
    "| Airports | 57,421 rows by 12 columns | The airport dataset provides airport metadata and identifiers necessary for joins. |  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bf00810-82c6-4f4f-986b-2c66aca149c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data dictionary\n",
    "\n",
    "This section defines the variables from each source that we used for our initial modeling and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc02a1ca-2f6a-48fe-9e59-3f91b386c3ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Flights data\n",
    "\n",
    "The flights data provide metadata for a given flight, and will also help us to study time-series trends and aggregate delay statistics by characteristics such as airport and airline. The below definitions were informed by DoT documentation [4].\n",
    "\n",
    "| Column |  Raw Data Type | Meaning | Intended Use |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| QUARTER | Integer | Quarter | Categorical variable to capture seasonal-periodic trends |\n",
    "| MONTH | Integer | Month | Categorical variable to capture month-periodic trends |\n",
    "| DAY_OF_WEEK | Integer | 1-7: Monday-Sunday | Categorical variable to capture week-periodic trends |\n",
    "| FL_DATE | String | Flight date | Used in flight timestamp UTC conversion |\n",
    "| OP_UNIQUE_CARRIER | String | Unique flight carrier ID | Airline categorical variable |\n",
    "| TAIL_NUM | String | Aircraft tail number (registration code) | Create time-based tracking features |\n",
    "| ORIGIN | String | Origin airport IATA code | Join to airports data; create route tracking features; match to seasonal components  |\n",
    "| DEST | String | Destination airport IATA code | Join to airports data; create time-based tracking feature |\n",
    "| CRS_DEP_TIME | Integer | Scheduled departure time (local, HHMM format) | Create time-based tracking features |\n",
    "| DEP_TIME | Integer | Actual departure time (local, HHMM format) | Create time-based tracking features |\n",
    "| DEP_DELAY | Double | Departure delay (min) | Define Boolean departure disruption status; create time-based tracking features |\n",
    "| TAXI_OUT | Double | Time taxiing out (min) | Create time-based tracking features |\n",
    "| TAXI_IN | Double | Time taxiing in (min) | Create time-based traffic flow |\n",
    "| CRS_ARR_TIME | Integer | scheduled arrival time (local, HHMM format) | Create time-based tracking features |\n",
    "| ARR_TIME | Integer | Actual arrival time (local, HHMM format) | Create time-based tracking features |\n",
    "| ARR_DELAY | Double | Arrival delay (min) | Create time-based tracking features |\n",
    "| CANCELLED | Double | 1.0/0.0: Cancelled/not cancelled | Define Boolean departure disruption status |\n",
    "| CRS_ELAPSED_TIME | Double | Scheduled flight duration (min) | Represent anticipated flight length; create time-basd tracking features |\n",
    "| ACTUAL_ELAPSED_TIME | Double | Actual flight duration (min) | Create time-based tracking features |\n",
    "| AIRTIME | Double | Time between take-off and landing (min) | Represent flight length |\n",
    "| DISTANCE | Double | Distance between origin and destination airports | Represent flight length |\n",
    "| YEAR | Integer | Year | Time series feature engineering |\n",
    "| DAY_OF_MONTH ||||\n",
    "| ORIGIN_CITY_NAME ||||\n",
    "| DEST_CITY_NAME ||||\n",
    "\n",
    "We chose to drop some variables from the full flights table based on redundancy, the proportion of missing values, and relevance to our analysis. These include alternate representations of airport and airline ID's and diversion information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f88ec66-4ad2-427a-80f3-888eb647f53e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Weather data\n",
    "\n",
    "The weather data allows us to define weather conditions relevant to an individual flight, as well as characterize longer-term regional weather trends. The below definitions were informed by NOAA documentation [2] and [3].\n",
    "\n",
    "| Column |  Raw Data Type | Meaning | Intended Use |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| STATION | String | Weather station ID | Key for joining to stations data |\n",
    "| DATE | String | Date the time (UTC) of weather report | Filter weather reports in time |\n",
    "| YEAR | Int | Year | Time series feature engineering |\n",
    "| LATITUDE | String | Station latitude (degrees North) | Characterize station location |\n",
    "| LONGITUDE | String | Station longitude (degrees East) | Characterize station location |\n",
    "| REPORT_TYPE | String | Weather report type | Filter to relevant report types |\n",
    "| HourlyDewPointTemperature | String | Dew point temperature (degrees F) | Define weather conditions |\n",
    "| HourlyDryBulbTemperature | String | Air temperature (degrees F) | Define weather conditions |\n",
    "| HourlyPrecipitation | String | Precipitation amount (in) | Define weather conditions |\n",
    "| HourlyPresentWeatherType | String | String code defining present weather *e.g.* rain or hail | Parse report to fill in missing information |\n",
    "| HourlyPressureChange | String | Change in pressure (in Hg) | Define weather conditions |\n",
    "| HourlyPressureTendency | String | Categorical characterization of recent pressure change | Define weather conditions |\n",
    "| HourlyRelativeHumidity | String | Relative humidity (percentage) | Define weather conditions |\n",
    "| HourlyVisibility | String | Horizontal visibility (mi) | Define weather conditions |\n",
    "| HourlyWetBulbTemperature | String | Wet bulb temperature (degrees F) | Define weather conditions |\n",
    "| HourlyWindGustSpeed | String | Wind gust speed (mph) | Define weather conditions |\n",
    "| HourlyWindSpeed | String | Wind speed (mph) | Define weather conditions |\n",
    "\n",
    "We chose to drop some variables from the full weather table based on redundancy, the proportion of missing values, and relevance to our analysis. These include alternate station identifiers, daily and monthly averages, and station backup/maintenance information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e841ecd-c8f2-4dfe-bb9c-64a7dd2cde8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Weather station data\n",
    "\n",
    "The weather station data defines the distances from various weather stations to various airports.\n",
    "\n",
    "| Column |  Raw Data Type | Meaning | Intended Use |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| station_id | String | Weather station ID | Key for joining to weather data |\n",
    "| lat | Double | Station latitude (degrees North) | Characterize station location |\n",
    "| lon | Double | Station longitude (degrees East) | Characterize station location |\n",
    "| neighbor_name | String | Airport name | Sanity check for joins |\n",
    "| neighbor_state | String | Airport state | Sanity check for joins |\n",
    "| neighbor_call | String | Airport ICAO code | Key for joining to airport data |\n",
    "| neighbor_lat | Double | Airport latitude (degrees North) | Characterize airport location |\n",
    "| neighbor_lon | Double | Airport longitude (degrees East) | Characterize airport location |\n",
    "| distance_to_neighbor | Double | Distance (mi) from station to airport | Find weather stations near a given airport |\n",
    "\n",
    "\n",
    "We chose to drop some variables from the full stations table based on redundancy and relevance to our analysis. These include alternate station and airport identifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "743d4782-4027-4ab5-8a96-db0ec8163f98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Airport data\n",
    "\n",
    "The airport dataset provides airport metadata and identifiers necessary for joins.\n",
    "\n",
    "| Column |  Raw Data Type | Meaning | Intended Use |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| ident | String | Airport ICAO code | Join to stations data |\n",
    "| type | String | Airport type | Characterize airport operations |\n",
    "| name | String | Airport name | Sanity check for joins |\n",
    "| continent | String | Airport continent | Filtering |\n",
    "| iso_country | String | ISO code of airport country | Filtering |\n",
    "| iso_region | String | ISO code of airport region | Filtering and sanity check for joins |\n",
    "| iata_code | String | Airport IATA code | Join to flights data |\n",
    "| coordinates | String | Airport latitude and longitude | Characterize airport location |\n",
    "\n",
    "We chose to drop some variables from the full airports table based on redundancy and relevance to our analysis. These include alternative identifiers and local, categorical location codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1c6489a-8a1d-4064-bc25-56c57b79a7c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Joining strategy\n",
    "\n",
    "We opted for joining flights data with weather observations instead of using OTPW data because of two reasons: \n",
    "* First, OTPW provides only weather at ORIGIN and we needed to incorporate weather conditions at the DESTINATION as well.\n",
    "* Second, OTPW provides the weather at the scheduled departure time which could lead to leakage problems. \n",
    "\n",
    "To achieve this, we developed a pipeline with multiple checkpoints as per the following steps:\n",
    "\n",
    "1. Creating a UDF to get time zones using airport’s latitude and longitude from the `coordinates` column in the Airports codes table and saved the results in a helper table that included `ICAO` or , `latitude`, `longitude`, and `timezone` with 2,237 unique airports.\n",
    "2. Cleaned and deduplicated the flights data, filtering for only the necessary features (dimentions before (14,844,074 x 109) and after (7,422,037 x 40)).\n",
    "3. Using the `ORIGIN` and `DEST` IATA codes, we joined the flights data with the airports codes table on `iata_code` twice; once for the origin and once for the destination to obtain the `icao_code` code for both locations along with `type`, `iso_region` columns as well with 100% match rate.\n",
    "4. Re-calculated the distance in *Kilometer* between each combination of the weather stations and Airports in the Staions dataset using the Haversine function. \n",
    "5. Before joining the flights data with the stations data, we identified the the missing `icao_codes` that doesn't exist in the stations table (7 airports in one year data). then added them to the stations table and calculated the haversine distance using the coordinated from te Airport codes table and saved the results to disk to avoid doing this step again in the future.\n",
    "6. Identified the closest weather station for each airport by filtering the stations table based on proximity first. That reduced this data set from approximatly 5 million rows to only 2,236 row which appoximatly the count of the unique airports in the one year dataset instead of using the whole stations data to reduce the shuffle during the join.\n",
    "7. Joined the flights data with the stations table to retrieve the `station_id`, `station_lat`, `station_lon`, `airport_lat`, `airport_lon`, and `station_distance` to the airport for both origin and destination.\n",
    "8. With location data in place, we first checked for missing `icoa_code` that exist in our flight data but not in our time zones helper table, found the time zones, and resaved the table for future use. Then we incorporated time zone `timezone` information by joining the flights data with our helper table on the `icoa_codes`. This allowed us to convert the scheduled departure time to UTC `sched_depart_utc` and calculate the timestamps for UTC-2 `two_hours_prior_depart_UTC` and UTC-4 `four_hours_prior_depart_UTC` using UDFs.\n",
    "9. Preprocessed the weather dataset by filtering for selected features, converting the date and time to UTC, and ensuring that only station-date combinations relevant to flights were retained which helped us reduce the weather data from (59,270,147 x 130) to (4,437,279 x 25) for the one year flights data.\n",
    "10. Joined the flights data with the weather data twice; once for the origin and once for the destination by matching the weather station ID and selecting only weather records with timestamps between UTC-4 and UTC-2 before departure. Please refer to the weather features selected in the previouse section. \n",
    "\n",
    "The Flights and weather join took approximately 26 minutes with 3-6 workers and resulted in a data frame with the dimenstion (7,422,037 x 117) with a Parquet file size approximately 1.79 GB for the the one year data set.\n",
    "\n",
    "All location specific column names were prefixed with `origin_` or `dest_` to indicate which location the information belongs to. \n",
    "\n",
    "To validate the pipeline, we first tested with a three-month dataset before scaling up to a full year, ensuring accuracy at each step. Throughout the process, we conducted quality checks to maintain data integrity and verify join match rates. All joins achieved a **100% match rate**, except for the weather data join, which had a **99.86% match rate** for both origin and destination. The pipeline successfully integrated flights with weather observations in a way that maintains data lineage and reliability, providing a solid foundation for our feature engineering step.\n",
    "\n",
    "Please refer to [Join Pipline notebook](https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/905158478261859?o=4021782157704243) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c847651-f479-4904-8c83-5a71d1401999",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<div style=\"text-align: center; line-height: 6; padding-top: 30px;  padding-bottom: 30px;\">\n",
    "<img src=\"https://github.com/bakr-UCB/261-Final-Project/blob/main/reports/figures/Join%20Pipeline.jpeg?raw=true\" alt=\"Join Pipeline\" style=\"width: 200px\">\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aa1b387-258d-408d-8956-ce950ba155bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5df2394c-f700-41c0-8cda-c8a73dc9b9e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "446e0a07-8fdb-4d09-8616-4b67e86e6c46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Missing Value Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edc9333d-e6cd-4249-bfc8-6c6465cdc5be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Weather\n",
    "\n",
    "The most critical missing values in the weather data were location-based; without latitude or longitude information we could not match the observation to the nearest airport. To identify stations, we extracted the USAF and WBAN codes from the first and second halves of the given weather station ID and parsed the ICAO code from the text report column (\"REM\"). We then matched whichever attribute was available to the stations dataset to fill in identifying information to the weather data and filtered out stations not in the United States or its territories. Missing feature observations in the weather dataset could be derived from sensor malfunctions and were often compounded to result in several hours or days in a row of missing data, even despite prolific duplicates. Duplicates are defined as multiple reports emitted from the same station at the same time. Therefore, our deduplication rule was simply to keep the record with the least null values in the hourly-level columns (our columns of interest). The de-duplicated dataset with location identifiers was then used as the weather base for the join. \n",
    "\n",
    "To address missing values in the weather data used for modeling, we first parsed the remarks column which contains METAR reports to extract relevant values. In cases where the METAR reports contained insufficient information or were also missing, we prioritized spatially-based imputation. This decision was based on the fact that the weather data matched to each flight was already two hours stale, limiting the usefulness of interpolation over time. Airports were geohashed using the python-geohash package at a precision level of 2, which clusters airports into coarse regional buckets to enable spatially coherent imputation. A more granular precision level resulted in not enough airports per bucket, whereas the less granular level was too broad and would not adequately capture region-specific weather conditions. For each missing weather observation, we attempted to impute values by pulling the most recent non-null weather reports timestamped between 2–6 hours prior to the flight's scheduled departure from other airports within the same geohash bucket.[**add why**] In cases where multiple stations within the geohash region had valid reports in that time window, we selected the most recent single record rather than computing an average, to reduce computational complexity. In cases where all stations in a region were down—due to widespread outages or technical issues—we implemented a fallback strategy by computing an exponential moving average (EMA) over the last 8 non-null records prior to the missing timestamp. This parameter was tuned to sufficiently capture remaining nulls without being unnecessarily wide. We chose the EMA approach to balance responsiveness to recent trends with the need to smooth over noise. Importantly, this method does not introduce label leakage: because all weather data were sourced from a 2–4 hour window prior to each flight's scheduled departure, no future data relative to the prediction target was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8650bac6-9327-4251-ae57-f83f695950ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Flights\n",
    "\n",
    "The flights dataset had true duplicates for each record, which was expected due to its information being recorded at origin and destination airports. The columns attributing delay minutes to causes (carrier, NAS, weather, security, late aircraft) were missing over 50% of their values, so we elected not to use them in the analysis. Time-related columns like arrival time, actual elapsed time, or departure time contained missing values only in the case of cancelled flights, or, in rare cases, diverted flights **[add diverted flight info here]**. Therefore it made sense that these values should be null. The TAIL_NUM column is essential for relating multiple flights by the same aircraft. Less than 1% of the values were missing, so nulls were treated as a missing value indicator which was inherited by dependent features. We also encountered cases where the same aircraft appeared scheduled to depart to different destinations at the same UTC departure timestamp. These duplicates were caused by cancellations or reassignment due to delays, likely reflecting inconsistencies from how system snapshots were recorded. [**describe non-cancelled example**]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86dde4eb-b47a-4d78-8c25-a0128f9a256b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4700107c-dc91-4385-a356-7b77d44d1ff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Shruti put in plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c17e20d7-5d75-408b-bca4-533408c9192c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Feature Engineering\n",
    "\n",
    "To augment the features available natively in the flights and weather datasets, we engineered features related to prior flights and seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f082feba-79b6-48d6-92ae-8c78d53dc251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prior Flight Features\n",
    "\n",
    "##### Overview\n",
    "Our primary modeling focus was on incorporating recency features, based on the hypothesis that operational status indicators from the preceding flight leg—such as whether the aircraft was delayed, cancelled, departed, or arrived—would be highly predictive of disruption outcomes at the current origin. This decision was further supported by initial exploratory data analysis (discussed further below): Spearman correlation coefficients between raw features and the target variable revealed limited signal in most static flight attributes, and distributional comparisons showed little meaningful variation. This aligns with domain intuition: disruptions in the aircraft’s prior leg are likely to propagate and impact on-time performance at the next origin. [**cite something to back this up too**]\n",
    "\n",
    "Among the recency-based features we created, we selected the following estimates (i.e., calculated only from information known at or before 2 hours before departure) for modeling:\n",
    "\n",
    "1. Binary indicators capturing the prior flight’s status:\n",
    "    - Whether it departed from its previous origin\n",
    "    - Whether it was delayed at its previous origin\n",
    "    - Whether it was cancelled at its previous origin\n",
    "    - Whether it arrived at the current origin\n",
    "\n",
    "2. Continuous timing features (in minutes):\n",
    "    - Departure delay at the previous origin\n",
    "    - Air time of the prior flight\n",
    "    - Turnaround time between the prior arrival and scheduled departure of the current flight\n",
    "\n",
    "\n",
    "When incorporating aircraft tracking data, we focused on addressing two major concerns: data quality issues and leakage.\n",
    "\n",
    "_Data Quality_\n",
    "\n",
    "We identified inconsistencies in the sequential mapping of aircraft routes: in [*X*] cases, the destination of a previous flight did not match the origin of the subsequent recorded flight for the same aircraft. For example, a record might show an aircraft arriving at Airport B from Airport A, followed by a record showing it departing from Airport C to Airport D. These records indicated unrecorded intermediate flights and motivated us to introduce an additional flag for unrecorded flights depending on whether the aircraft's previous flight occurred over a day ago. \n",
    "\n",
    "To reduce the risk of incorporating misleading features derived from incomplete route chains, we therefore filled in lagged timestamp features as missing instead of extracting them if:\n",
    "1) the destination of the last recorded flight for an aircraft did not match the origin of its next recorded flight, and/or\n",
    "2) the last recorded flight for an aircraft occurred more than 24 hours prior to the 2-hour window before its next scheduled departure\n",
    "\n",
    "This threshold was informed by observed patterns: missing segments frequently appeared after prolonged gaps in activity, often spanning a full day. These filters helped reduce the risk of incorporating misleading features derived from incomplete route chains.  [**add relevant stats**]\n",
    "\n",
    "_Leakage_\n",
    "\n",
    "We only wanted to incorporate information that would be known at the threshold T-2 hours before the scheduled departure time. We also made a core assumption that the airport would know, at this threshold, whether the prior flight was cancelled. This was based on research about cancellations [**cite**] and also the very low quantity of flights that were scheduled to depart and land within the 2 hour window [**stats**]. We also assume that all previous flights are scheduled more than 2 hours before the current flight. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f887174-0dda-4dc6-bd9b-50e302121437",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "##### Methods\n",
    "\n",
    "We began by calculating a threshold timestamp: 26 hours prior to each flight’s scheduled departure. Using this, we generated lagged features over the aircraft tail number (i.e., unique aircraft identifier), including origin and destination airports, scheduled and actual departure times, delays, and arrival times.\n",
    "\n",
    "Contingent on not meeting the missing route information criteria, we created the following features\n",
    "\n",
    "_Cancellation_: \n",
    "- Indicator (boolean): A binary flag indicating whether the previous flight was cancelled. No restriction on timing was applied, as cancellations are often logged early and knowing about them before the prediction threshold (2 hours prior to departure) aligns with our use case.\n",
    "\n",
    "_Delays:_\n",
    "- Continuous variable (minutes): Estimated delay of the prior flight, computed based on available data:\n",
    "\n",
    "    - If the prior flight scheduled departure and recorded departure were both before the threshold, we  simply used the true recorded delay value.\n",
    "    - If the prior flight was scheduled to depart before the threshold, but did not have a recorded true departure time yet, we did not attempt to estimate what the further delay might be. Instead, we essentially made the assumption that it departed at the 2 hours prior UTC time by recording the delay as the difference between the threshold and the prior flight scheduled departure time. In the future, this could be fine tuned by setting a default parameter relative to the estimated prior flight time or estimated based on some other indicator, but it only accounted for [**x% of cases**] and we did not want to introduce additional computational overhead.\n",
    "    - If the prior flight was scheduled to depart after the threshold, and the route information met the standard, we assumed there would be no delay, as we do not have cause to believe there might be. This could also be tuned by calculating average delay for that route, but as this only represents [**x% of cases**], we similarly hesitated to introduce computationally intensive operations.\n",
    "\n",
    "    If the prior flight was cancelled or the missing route information conditions were met, leaving us with no information on the prior flight, \n",
    "    \n",
    "    - we filled in the delay calculation with the last non-null delay calculation occurring on the same route. Knowing that we're missing information gives us cause to anticipate a delay or operational disruptions, so we fill in with the average info for how a flight is delayed before embarking on the current route. [**more justification on why this is filled in but not the others**]\n",
    "- Indicator (boolean): If the prior flight wa estimated to have been delayed, or known to have been cancelled, the delay indicator was set to True.\n",
    "\n",
    "\n",
    "_Departures_: \n",
    "\n",
    "- Indicator (boolean): If and only if the known prior flight departure time met the data quality standard and was before the threshold the boolean prior flight departure indicator was set to true. \n",
    "\n",
    "- Estimator (timestamp): The prior departure time was estimated by adding the estimated delay calculation to the scheduled departure time.\n",
    "\n",
    "_Arrivals_:\n",
    "\n",
    "- Indicator (boolean): If and only if the prior flight known arrival time met the data quality standard and was before the threshold, the indicator was set to True.\n",
    "\n",
    "- Estimator (timestamp):\n",
    "    - If the prior flight arrived before the 2-hour window, we filled this in with the true arrival time.\n",
    "    - If the prior flight was known to have departed before the threshold, we filled this in by adding the estimated elapsed time to the known departure time.\n",
    "    - Otherwise, we simply added the estimated elapsed time to the estimated departure time.\n",
    "\n",
    "\n",
    "_Turnaround time_: \n",
    "\n",
    "- To calculate the estimated amount of time the aircraft had between arriving and departing, we took the difference between the estimated arrival time of the previous flight and the estimated departure time of the current flight. If the previous flight was not confirmed, we again estimated this from the calculated turnaround time from the last record of this route being flown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23145961-98e2-49eb-b736-ec1a76ccae5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8714de08-a8c5-4fb9-8e56-fa3f39d07b0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Seasonality Features\n",
    "\n",
    "We expect fluctuation in flight delays on a number of timescales, as travel demand and airports' ability to meet that demand vary over time. For example, delays vary throughout the day with the volume of traffic at an airport, and as delays from earlier in the day impact later flights. Delays also vary throughout the year as travel habits change--*e.g.* consider spring break, winter holidays, summer travel, or ski trips. We have engineered seasonality features to capture these effects quantitatively, in order to provide the model input about what seasonal effects may be at play for a given record.\n",
    "\n",
    "To produce these features, we trained seasonality models using the Prophet Python library [**CITE???**]. For a given training dataset (discussed below), a Prophet model was fit for each airport using the UTC departure time as the time field and departure delay in minutes as the outcome variable. Each model assumed linear growth, an uncertainty interval width of 90%, and included weekly, daily, and yearly seasonality components. Each model was used to forecast predictions one week into the future, with an hourly frequency (*i.e.* to get the daily and weekly components for each hour throughout the week). These components, along with the airport identifier, were stored in a lookup table. The example below shows the seasonality components for Boston Logan International Airport (BOS), trained on the January-September 2019 training set.\n",
    "\n",
    "<div style=\"text-align: center; line-height: 6; padding-top: 30px;  padding-bottom: 30px;\">\n",
    "<img src=\"https://github.com/bakr-UCB/261-Final-Project/blob/main/reports/figures/BOS_seasonality_ex.png?raw=true\" alt=\"ML Pipeline\" style=\"width: 200px\">\n",
    "<div>\n",
    "\n",
    "To apply these seasonality components to the modeling data, the modeling data was joined to this lookup table on airport, day of week, and hour of day, to get the relevant daily and weekly seasonality components for each record. The following table summarizes the resulting features.\n",
    "\n",
    "| Feature |  Data Type | Description |\n",
    "|:---:|:---:|:---:|\n",
    "| daily | Float | Daily seasonality component (offset from trend) in minutes |\n",
    "| weekly | Float | Weekly seasonality component (offset from trend) in minutes |\n",
    "\n",
    "Because these seasonality components are *trained* from data, we had to be mindful of leakage when creating these features. To ensure that our cross-validation and overall test sets were not contaminated with test data information, we trained a seaparate seasonality for each cross-validation fold and the overall dataset, utilizing the relevant training dataset in each case (*e.g* the seasonality trained on CV fold 1 training data was applied to the CV fold 1 training and test sets).\n",
    "\n",
    "The below figure summarizes the Spearman correlation of the seasonality features with the outcome variable for the full 2019 (1 year) dataset. We see that daily seasonality is moderately correlated with our outcome, but the weekly feature is only very weekly correlated.\n",
    "\n",
    "<div style=\"text-align: center; line-height: 6; padding-top: 30px;  padding-bottom: 30px;\">\n",
    "<img src=\"https://github.com/bakr-UCB/261-Final-Project/blob/main/reports/figures/seasonality_correlation.png?raw=true\" alt=\"ML Pipeline\" style=\"width: 200px\">\n",
    "<div>\n",
    "\n",
    "Note that we have chosen to omit yearly seasonality from our feature set here because our full training set has data only for 9 months of the year. Once our training data spans at least a full year, we will add yearly and holiday-based seasonality features.\n",
    "\n",
    "Please refer to the section **Train seasonality models for each fold** in [this notebook](https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1556213624087093?o=4021782157704243#command/1556213624087105) for the code used to generate the seasonality features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3480912-09bb-49f2-b4b9-92d3d2ee22e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Engineering Next Steps\n",
    "\n",
    "Given the correlation of the prior flight features to our outcome, recency and frequency features show promise in providing effective predictors. We'd like to extend this idea to airport-related features, *e.g.* capturing the average delay and proportion of flights delayed at the origin airport between 2 and 4 hours prior to a scheduled flight. We suspect this will provide valuable information to the model about broader, airport-wide conditions that may lead to delay.\n",
    "\n",
    "In addition, we would like to incorporate graph-based features. **SPECIFIC GRAPH-BASED FEAURE???**\n",
    "\n",
    "Finally, as mentioned above, we will augment our existing seasonality models with yearly and holiday-based components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92e73677-1c7d-4bd5-a53d-ae0056d9a489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f756fae-4692-4660-a18a-3340889a7a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### _7. Modeling Pipelines Rubric_\n",
    "- -- A visualization of the modeling pipeline (s) and sub pipelines if necessary\n",
    "- -- Families of input features and count per family\n",
    "- -- Number of input features\n",
    "- -- Loss function used (data loss and regularization parts) in latex\n",
    "- -- Number of experiments conducted\n",
    "- -- Describe cluster size, and how many minutes it takes to build each model type.\n",
    "- -- Experiment table with the following details per experiment:\n",
    "- ----- Baseline experiment\n",
    "- ---- The families of input features used\n",
    "- ----- For train/valid/test record the following in a Pandas DataFrame: (?? rubric doesn't list anything here ??)\n",
    "- ---- List Metrics used along with: their Latex equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c3b897b-9765-4dce-91ab-f58b3589d227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Modeling Pipeline\n",
    "\n",
    "The following steps and diagram outline our end-to-end modeling workflow. The remainder of this section provides additional details for each step.\n",
    "\n",
    "1. **Ingestion:** Load raw data into Spark DataFrames\n",
    "2. **Feature selection:** Drop unnecessary columns\n",
    "3. **Join:** Combine data sources into joined DataFrame\n",
    "4. **Feature engineering and imputation, part I:** Add \"non-trained\" engineered features and fill missing values using time series methods\n",
    "5. **Split:** Divide data into training, validation, and test splits\n",
    "6. **Sample:** Undersample training data\n",
    "7. **Feature engineering and imputation, part II:** Incorporate or fill features based on training data characteristics\n",
    "8. **Define machine learning pipelines:** Create Spark Pipeline objects for feature transformations and modeling\n",
    "9. **Hyperparameter tuning:** Use cross-validation to train model that balances performance and generalizability\n",
    "10. **Model training:** Train final model(s) using chosen hyperparameters\n",
    "11. **Model evaluation:** Assess trained models on test data\n",
    "\n",
    "<div style=\"text-align: center; line-height: 10; padding-top: 30px;  padding-bottom: 30px;\">\n",
    "<img src=\"https://github.com/bakr-UCB/261-Final-Project/blob/main/reports/figures/ml_pipeline.png?raw=true\" alt=\"ML Pipeline\" style=\"width: 500px\">\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59c8041c-16b3-43fb-8d6d-17aada9839ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ingestion, Feature Selection, and Join\n",
    "\n",
    "Raw data were loaded from the provided parquet files and unnecessary columns were dropped on the basis of relevance (as discussed in **Data Dictionary**) or missing value status (as discussed in **Missing Value Analysis**). The weather and flights data were joined (as discussed in **Joining Strategy**) and saved out to an intermediate parquet file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec94d0b0-4ead-4cb4-b2a8-ea69b363dcb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Engineering and Imputation, part I\n",
    "\n",
    "In our processing pipeline, we make the distinction between processing steps that are \"trained\" verus \"non-trained.\" Non-trained processing steps are those which can be applied to a single record in isolation, or which depend only on past-time information for a given record. These steps can be performed before splitting the data without introducing leakage.\n",
    "\n",
    "In contrast, trained features are those which are trained on data from the entire dataset, and therefore must be trained on the training set only and applied after splitting the data to avoid test set leakage.\n",
    "\n",
    "In \"part I\" of feature engineering and imputation, we address the non-trained feature processing steps. These include the weather data imputation and prior flight feature engineering, as discussed in the sections **Missing Value Analysis** and **Prior Flight Features**, respectively. Results from this step were written out to an intermediate parquet file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dc0ef56-3ecd-45ad-81e1-f40892c24dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Train, Test, and Cross Validation Splits\n",
    "\n",
    "For the 2019 (1 year) dataset, we have trained our machine learning models on the first 9 months of the year and tested on a held out set from the last 3 months of the year. See the table below for the UTC time limits of data included in each split.\n",
    "\n",
    "To validate our models and tune hyperparameters, we used blocking time-based cross validation (CV) with 5 folds, and 20% (by number of records) overlap between the folds (*i.e.* 20% of the fold 1 training records are also present in the fold 2 training data, and so on). Each fold had approximately 1,068,100 records in train and test each, and the full train and test sets containted 5,554,218 and 1,867,819 records, respectively. See the table below for the UTC time limits of data included in each split, for each fold.\n",
    "\n",
    "| Modeling Case |  Train Time Period | Test Time Period |\n",
    "|:---:|:---:|:---:|\n",
    "| CV Fold 1 | 12/31/18 21:30 - 2/26/19 20:15 | 2/26/19 20:15 - 4/19/19 23:30 |\n",
    "| CV Fold 2 | 2/15/19 18:00 - 4/9/19 17:10 | 4/9/19 17:10 - 5/31/2019 21:40 |\n",
    "| CV Fold 3 | 3/30/19 01:42 - 5/21/19 14:05 | 5/21/19 14:05 - 7/11/19 16:35 |\n",
    "| CV Fold 4 | 5/10/19 22:55 - 7/1/2019 01:00 | 7/1/19 01:00 - 8/20/19 00:58 |\n",
    "| CV Fold 5 | 6/21/19 00:25 - 8/9/19 23:55 | 8/9/19 23:55 - 9/30/19 23:59 |\n",
    "| Overall | 12/31/18 21:30 - 09/30/19 23:59 | 10/01/19 00:00 - 01/01/2020 10:20 |\n",
    "\n",
    "Please refer to the section **Get cross-validation splits** in [this notebook](https://dbc-fae72cab-cf59.cloud.databricks.com/editor/notebooks/1556213624087093?o=4021782157704243#command/6823299216257862) for the code to calculate the cross-validation split times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "880498d6-bf49-4f4a-ad14-1791fb0c5cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sampling Strategy\n",
    "\n",
    "The computations of datapoint distances used in oversampling/SMOTE is not favorable considering the size of our data, so we plan to use undersampling to address the class imbalance in our outcome variable. Because we will need to undersample drastically to reach a class balance we will we be intentional about how we sample to ensure variables of interest are not disproportionally influenced due to the time seiries quality of the data. This may look like making sure every airport or every day is still represented, but plan to explore these strategies further during Phase III. So far, we have used a simple random undersampling approach to balance the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7b3bbff-ecbb-4d63-b6d3-2229c7bdd6ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Engineering and Imputation, part II\n",
    "\n",
    "Here, we address the \"trained\" processing steps discussed above. This includes applying the seasonality models (as discussed in the section **Seasonality Features**) that were trained on the training data, and doing any median-based imputation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78c69f3f-f7a8-4fe1-8c2a-7163965bad5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Machine Learning Pipelines\n",
    "\n",
    "We used the Pyspark Pipelines API [**CITE???**] to transform our chosen features and train machine learning models.\n",
    "\n",
    "#### Feature Families\n",
    "\n",
    "We explored a variety of models, utilizing different families of features. The below table summarizes the feature families, as well as which features were used in each machine learning model we tested (BL = baseline, AF = additional features, INT = interaction terms, REG = regularization; see additional information in next section).\n",
    "\n",
    "| Feature Family | Feature | Type | Raw or Engineered | BL | AF | INT | REG |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| **Numeric Weather Features** | origin_HourlyDewPointTemperature | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyDryBulbTemperature | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyPrecipitation | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyPressureChange | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyRelativeHumidity | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyVisibility | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyWetBulbTemperature | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyWindGustSpeed | Float | Raw | x | x | x | x |\n",
    "|  | origin_HourlyWindSpeed | Float | Raw | x | x | x | x |\n",
    "| **Flight Metadata** | OP_UNIQUE_CARRIER | Categorical | Raw | x | x | x | x |\n",
    "|  | ORIGIN_ICAO | Categorical | Raw | x | x | x | x |\n",
    "|  | DEST_ICAO | Categorical | Raw | x | x | x | x |\n",
    "|  | origin_type | Categorical | Raw | x | x | x | x |\n",
    "|  | dest_type | Categorical | Raw | x | x | x | x |\n",
    "|  | DISTANCE | Float | Raw | x | x | x | x |\n",
    "|  | CRS_ELAPSED_TIME | Float | Raw | x | x | x | x |\n",
    "| **Date Information** | YEAR | Categorical | Raw | x | x | x | x |\n",
    "|  | QUARTER | Categorical | Raw | x | x | x | x |\n",
    "|  | MONTH | Categorical | Raw | x | x | x | x |\n",
    "|  | DAY_OF_MONTH | Categorical | Raw | x | x | x | x |\n",
    "|  | DAY_OF_WEEK | Categorical | Raw | x | x | x | x |\n",
    "| **Seasonality Components** | daily | Float | Engineered | x | x | x | x |\n",
    "|  | weekly | Float | Engineered | x | x | x | x |\n",
    "| **Prior Flight Features** | priorflight_elapsed_time_calc_raw | Float | Engineered |  | x | x | x |\n",
    "|  | turnaround_time_calc | Fload | Engineered |  | x | x | x |\n",
    "|  | priorflight_depdelay_calc | Float | Engineered |  | x | x | x |\n",
    "|  | priorflight_isdeparted | Boolean | Engineered |  | x | x | x |\n",
    "|  | priorflight_isarrived | Boolean | Engineered |  | x | x | x |\n",
    "|  | priorflight_isarrived_calc | Boolean | Engineered |  | x | x | x |\n",
    "|  | priorflight_isdelayed | Boolean | Engineered |  | x | x | x |\n",
    "|  | priorflight_isdelayed_calc | Boolean | Engineered |  | x | x | x |\n",
    "| **Interaction Terms** | TempPrecipitation | Float | Engineered |  |  | x | x |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Feature Transformations\n",
    "\n",
    "Our final feature set consisted of both numeric and categorical features, which were handled separately within the pipeline. Numeric features were scaled using Spark's MinMaxScaler. Categorical features were one-hot encoded using Spark's StringIndexer (maps text categories to integers) and OneHotEncoder (one-hot encodes integer categories). For some models, interaction terms were also added via Spark Interaction objects. The transformed numeric, categorical, and interaction features were assembed using Spark's VectorAssember, to be used as input to the classification object. For our baseline model, this was a Spark LogisticRegression object.\n",
    "\n",
    "**ADD SPARK PIPELINE DIAGRAM**\n",
    "\n",
    "#### Modeling\n",
    "\n",
    "Our final transformed features were input to a Spark LogisticRegression object to complete our pipeline and define the machine learning model. This final pipeline was fit using the training data, then \"transformed\" the test data to output predictions, which were evaluated as discussed in the section [WWW]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "717aaec2-d0e2-4058-8d0d-b4a2be2b1b85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Experiments Table\n",
    "| model |   input feautures  | metrics |\n",
    "|:---:|:---:|:---:|\n",
    "|x  |  y   |  z|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "629d285f-e8a0-446b-8f66-a4b74e609f6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Machine algorithms and metrics\n",
    "\n",
    "We have chosen to pursue a binary classification problem. Our outcome variable is a binary flag indicating whether or not a flight was either delayed (using the FAA definition of 15 or more minutes late) or cancelled. We choose to include cancellations in our \"delay\" case since they have similar consequences for our stakeholder in our business case of airport resource management.\n",
    "\n",
    "We are interested in four potential models: Logistic Regression, XGBoost, Random Forest, and Multi-Layer Perceptron. The logic regression model was chosen as our baseline model, as it provides a very simple, linear classification model against which the results of more complex algorithms can be compared. For more advanced methods we would like to create XGBoost, Random Forest, and Multi-Layer Perceptron models. The loss function for all models is a log loss/ cross entropy loss.\n",
    "\n",
    "In choosing an appropriate metric to evaluate our classification performance, we weighed the cost of each classification error:\n",
    "\n",
    "**Type I error** (*FP:* The model predicts a delay, but the flight departs on time) this may cause confusion and unnecessary changes from air traffic control. however, it's more acceptable if we are prioritizing caution and want to minimize unexpected delays.\n",
    "\n",
    "**Type II error** (*FN:* The model predicts the flight will be on time, but it ends up delayed) Passengers and crew aren’t prepared for the delay, potentially leading to missed connections, poor customer satisfaction, and operational disruptions. This type is more costly if unexpected delays cause major disruptions, and you aim to avoid them at all costs.\n",
    "\n",
    "We estimate that Type II errors are roughly twice as costly as Type I errors to our stakeholder, therefore we choose the F-beta metric with a beta value of 2, to reflect the emphasis on recall over precision.\n",
    "\n",
    "We will also consider Gini Impurity for the Random Forest model hypertuning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb645ff1-2474-4348-84e3-591fd9735abe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Logistic Function\n",
    "$$\\sigma(t) = \\frac{1}{1+\\exp(-t)}$$\n",
    "\n",
    "#### Binomial Cross Entropy Loss Function\n",
    "$$J(\\theta) = -\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}\\log(\\hat{p}^{(i)})+(1-y^{(i)})\\log(1-\\hat{p}^{(i)}))]$$\n",
    "\n",
    "#### Classification Metircs\n",
    "$$F\\beta-Score = \\frac{\\beta^2 + 1}{\\frac{\\beta^2(TP + FN)}{TP} + \\frac{TP+FP}{TP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da400c74-4868-41bc-b9e2-e7f7e6b30541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## _ML Pipelines Feedback_\n",
    "The Majority class baseline is too simple and not really useful in a business setting. Logistic Regression should be your baseline. I don't care too much about what cost function are you using, I care more about the effect of the loss in the model.\n",
    "The discussion of FP and FN is very goof, but before that you just listed all classification metrics, even accuracy, which SHOULD NOT BE USED AT ALL IN A IMBALANCE PROBLEM. The metric discussion has to be clear: what is the cost of FP vs FN, thus justifying the metric. Are you sure both are equally important for the customer? If not, you may want to use F Beta instead of F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d13661f-c70e-4638-9d53-7cee9cc4ba97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Feature Selection\n",
    "\n",
    "[Discuss any feature selection algos that were used, or justify why we didn't do feature selection ???]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "459f8d4c-36fe-43de-b84a-0dcd7400474b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Results\n",
    "- Please report the results of training (first three-quarters of the one-year dataset), and blind testing (the last quarter of the available one-year dataset).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f639a72-20b5-408c-aeb9-99b9e44cae11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Discussion of Results\n",
    "- The aim of the discussion section is to review experiments conducted and draw conclusions about key pipelines (supported by experimental results).. **Often, this part is the most important, simply because it lets the researcher take a step back and give a broader look at the experiment.** Do not discuss any outcomes not presented in the results part (not supported by experiments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53873aba-3052-45c8-9c61-87c4960d2f5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Conclusion\n",
    "- Expectations here are to address the following following in your conclusion (in about 150 words) in a main section by itself:\n",
    "- -- Restate your project focus explain why it’s important. Make sure that this part of the conclusion is concise and clear.\n",
    "- -- Restate your hypothesis (e.g., ML pipelines with custom features can accurately forecast .....)\n",
    "- -- Summarize the main points of your project: Remind your readers of your key contributions.\n",
    "- -- Discuss the significance of your results\n",
    "- -- Discuss the future of your project and closing thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19ab2815-fec4-47c5-bec2-bb65f3bae1c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a22fae-bac1-4d34-b639-e59d8a30bb90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bibliography\n",
    "\n",
    "<ol>\n",
    "    <li>\"Air Traffic.\" Federal Aviation Administration, 20 Apr. 2023, www.faa.gov/air_traffic.</li>\n",
    "    <li>\"Federal Climate Complex Data Documentation for Integrated Surface Data (ISD).\" NOAA NCEI, 12 Jan. 2018, https://www.ncei.noaa.gov/data/global-hourly/doc/isd-format-document.pdf. Accessed 16 Mar. 2025.</li>\n",
    "    <li>“Local Climatological Data (LCD) Dataset Documentation.” Local Climatological Data (LCD) Data, NOAA NCEI, www.ncei.noaa.gov/pub/data/cdo/documentation/LCD_documentation.pdf. Accessed 16 Mar. 2025.</li>\n",
    "    <li>\"Reporting Carrier On-Time Performance (1987-present).\" Bureau of Transportation Statistics, https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ. Accessed 16 Mar. 2025.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfa9aeb2-5be5-47cc-857e-c31370a53a1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PHASE 2 Project Report",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
