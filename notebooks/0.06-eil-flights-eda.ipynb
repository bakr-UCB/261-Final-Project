{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c1b46f4-bb4c-4f65-85fb-a5a2a61bb687",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Flights data EDA and feature engineering\n",
    "\n",
    "Erica Landreth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a06086ec-eca4-4c77-a896-9cf081f11f64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a1ce0d-69c7-4c41-9606-f67eadc6952d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_version = spark.version\n",
    "print(f\"Spark version: {spark_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da637cb5-8334-4811-a0ea-71aeaaef984a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark.sql.functions as F\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, StructType\n",
    "from prophet import Prophet\n",
    "from prophet.make_holidays import make_holidays_df\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from prophet.plot import plot_forecast_component\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time\n",
    "from pyspark.sql.functions import current_date\n",
    "from pyspark.sql.functions import lit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d07ec98-a7a9-42a7-b26f-ec9719efcea2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"dbfs:/student-groups/Group_4_1\"\n",
    "dataset = 'parquet_airlines_data_1y' # 1 year\n",
    "df = spark.read.parquet(f\"{folder_path}/interim/{dataset}_clean.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1d3ef1a-77c8-4abf-a8f9-ce35fb01308f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "920e9168-2ba8-4644-8ea3-b3d2335c9af5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# reminder of which colmns kept\n",
    "\n",
    "# core features: useful for ML features and/or feature engineering\n",
    "core_feats = [\"FL_DATE\",\"OP_UNIQUE_CARRIER\",\"TAIL_NUM\",\"OP_CARRIER_FL_NUM\",\"ORIGIN\",\"DEST\",\"CRS_DEP_TIME\",\"DEP_DELAY\",\"CRS_ARR_TIME\",\"ARR_DELAY\",\"CANCELLED\",\"DIVERTED\",\"CRS_ELAPSED_TIME\",\"AIR_TIME\",\"DISTANCE\"]\n",
    "# we may or may not end up using these, but they can't easily be recreated later, so we'll keep them to be cautious\n",
    "on_the_fence = [\"ORIGIN_AIRPORT_SEQ_ID\",\"DEST_AIRPORT_SEQ_ID\",\"TAXI_OUT\",\"TAXI_IN\"]\n",
    "# useful for time series analysis\n",
    "time_series = [\"QUARTER\",\"MONTH\",\"DAY_OF_MONTH\",\"DAY_OF_WEEK\",\"DEP_TIME_BLK\",\"ARR_TIME_BLK\",\"YEAR\"]\n",
    "# useful to sanity check that joins are successful\n",
    "sanity_check = [\"ORIGIN_CITY_NAME\",\"DEST_CITY_NAME\",\"ORIGIN_STATE_FIPS\",\"DEST_STATE_FIPS\"]\n",
    "# provides reasoning for cancellations, delays, and returns to gate\n",
    "delay_info = [col for col in df.columns if col.endswith(\"_DELAY\") and col not in core_feats] + [\"CANCELLATION_CODE\"] + [\"FIRST_DEP_TIME\",\"LONGEST_ADD_GTIME\",\"TOTAL_ADD_GTIME\"]\n",
    "    # Note: cancellation codes are: \"A\" for carrier-caused, \"B\" for weather, \"C\" for National Aviation System, and \"D\" for security"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af87e24c-cc9d-4d66-b1cc-6f7fd09a6447",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Characterizing outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d4562bd-9064-405e-a2b6-83b3b3fb2ab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcome_cols = ['DEP_DELAY','CANCELLED']\n",
    "outcome_info = df.select(outcome_cols + delay_info).toPandas()\n",
    "\n",
    "outcome_info['is_delayed'] = (outcome_info['DEP_DELAY'] >= 15)\n",
    "outcome_info['is_cancelled'] = (outcome_info['CANCELLED'] > 0)\n",
    "outcome_info['outcome'] = outcome_info['is_delayed'] | outcome_info['is_cancelled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a5102bb-0f2e-4e15-b89d-441a85948184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(outcome_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4ae2ff1-9903-4ccb-9d62-3aa96c9ef67d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(outcome_info.groupby(['is_delayed','is_cancelled']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26e08053-1979-41e9-a75f-a8c13e5549d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delay_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b8144b-611a-4c2a-81ed-73726248aa15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Explore how many flights are delayed, and, of the the delayed flights, how many have delay time attributed to various reasons. Understanding which \"reasons\" are often listed for a delay can guide which types of features we try to design, in order to capture some of those effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32505680-8675-411c-a221-fd80dca0b257",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [np.mean(outcome_info['outcome']), np.mean(np.logical_not(outcome_info['outcome']))]\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "ax.barh([''],data[0], color='black',height=0.25,edgecolor='black',label='Delayed')\n",
    "ax.barh([''],data[1], color='gray',height=0.25,edgecolor='black',left=data[0],label='Not Delayed')\n",
    "ax.set_xlabel('Proportion')\n",
    "ax.set_title('Proportion of delayed flights')\n",
    "ax.set_xlim((0,1))\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(0.5,-0.3),ncol=2)\n",
    "plt.show()\n",
    "\n",
    "reason_cols = [c for c in outcome_info.columns if \"_DELAY\" in c and c not in [\"DIV_ARR_DELAY\",\"DEP_DELAY\"]]\n",
    "# delayed = outcome_info[outcome_info['DEP_DELAY'] > 0][reason_cols].fillna(0)\n",
    "delayed = outcome_info[outcome_info['outcome']][reason_cols].fillna(0)\n",
    "for v in delayed.columns:\n",
    "    data = [np.mean(delayed[v] > 0), np.mean(delayed[v] <= 0)]\n",
    "\n",
    "    fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "    ax.barh([''],data[0], color='black',height=0.25,edgecolor='black',label='Delayed')\n",
    "    ax.barh([''],data[1], color='gray',height=0.25,edgecolor='black',left=data[0],label='Not Delayed')\n",
    "    ax.set_xlabel('Proportion')\n",
    "    reason = ' '.join(v.split('_')[0:]).lower()\n",
    "    ax.set_title(f'Proportion of delayed flights delayed by {reason}')\n",
    "    ax.set_xlim((0,1))\n",
    "    ax.legend(loc='upper center',bbox_to_anchor=(0.5,-0.3),ncol=2)\n",
    "    plt.show()\n",
    "\n",
    "# average delay amount attributed to each reason\n",
    "data = np.sum(delayed, axis=0)\n",
    "data = data.sort_values(ascending=False) / np.sum(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17efa019-ef85-4331-9736-7fabf0208a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "for idx,v in enumerate(data.index):\n",
    "    if idx == 0:\n",
    "        ax.barh([''],data[v],edgecolor='black',label=v.replace(\"_\",\" \"))\n",
    "    else:\n",
    "        print(data[delayed.columns[idx-1]])\n",
    "        ax.barh([''],data[v],edgecolor='black',label=v.replace(\"_\",\" \"),left=np.sum(data[data.index[:idx]]))\n",
    "ax.set_xlabel('Proportion')\n",
    "ax.set_title(f'Proportion of total delay minutes by DoT delay categories')\n",
    "ax.set_xlim((0,1))\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(0.5,-0.3),ncol=len(data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f449467a-2a7c-4f7b-a2c1-3045f1dd8bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Info on delay reasons from DoT data dictionary: https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ\n",
    "\n",
    "Greatest proportion of flights being delayed by carrier, NAS, or late aircraft.\n",
    "\n",
    "More notes on what the delay categories mean: https://www.bts.gov/topics/airlines-and-airports/understanding-reporting-causes-flight-delays-and-cancellations\n",
    "\n",
    "Verbatim descriptions from that website:\n",
    "\n",
    "\"Air Carrier: The cause of the cancellation or delay was due to circumstances within the airline's control (e.g. maintenance or crew problems, aircraft cleaning, baggage loading, fueling, etc.).\n",
    "\n",
    "Extreme Weather: Significant meteorological conditions (actual or forecasted) that, in the judgment of the carrier, delays or prevents the operation of a flight such as tornado, blizzard or hurricane.\n",
    "\n",
    "National Aviation System (NAS): Delays and cancellations attributable to the national aviation system that refer to a broad set of conditions, such as non-extreme weather conditions, airport operations, heavy traffic volume, and air traffic control.\n",
    "\n",
    "Late-arriving aircraft: A previous flight with same aircraft arrived late, causing the present flight to depart late.\n",
    "Security: Delays or cancellations caused by evacuation of a terminal or concourse, re-boarding of aircraft because of security breach, inoperative screening equipment and/or long lines in excess of 29 minutes at screening areas.\"\n",
    "\n",
    "NOTES:\n",
    "\n",
    "Interesting that \"weather delay\" only includes extreme weather; otherwise weather delays are lumped into the NAS category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "281bf454-d8d7-4d8c-a6b3-2d3ba198dccb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Visualize airport and weather station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98be4534-3d8b-4b13-8278-de87f960770e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load stations data\n",
    "df_stations = spark.read.parquet(f\"dbfs:/mnt/mids-w261/datasets_final_project_2022/stations_data/stations_with_neighbors.parquet/\")\n",
    "\n",
    "# load airports data\n",
    "df_airports = spark.read.option(\"header\",\"true\").csv(f\"dbfs:/mnt/mids-w261/airport-codes_csv.csv\")\n",
    "\n",
    "# get list of airports in stations data\n",
    "station_call = df_stations.select('neighbor_call').toPandas()\n",
    "\n",
    "# get weather station locations\n",
    "station_locs = df_stations.select('lat','lon','station_id').distinct().toPandas()\n",
    "\n",
    "# get airport locations\n",
    "airport_locs = df_airports.select('coordinates','ident').distinct().toPandas()\n",
    "\n",
    "# filter airports to those in stations\n",
    "airport_locs = airport_locs[airport_locs['ident'].isin(station_call['neighbor_call'])]\n",
    "\n",
    "# get airport lat/lon coordinates\n",
    "airport_locs[['lon', 'lat']] = airport_locs['coordinates'].str.split(',', expand=True)\n",
    "airport_locs['lat'] = airport_locs['lat'].astype(float)\n",
    "airport_locs['lon'] = airport_locs['lon'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b189a341-ca1f-437c-a4df-95a59a32c31b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plot stations and\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scattergeo(\n",
    "    lat=station_locs['lat'],\n",
    "    lon=station_locs['lon'],\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color='blue'\n",
    "    ),\n",
    "    name='Weather Stations'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scattergeo(\n",
    "    lat=airport_locs['lat'],\n",
    "    lon=airport_locs['lon'],\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color='red'\n",
    "    ),\n",
    "    name='Airports'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    geo=dict(\n",
    "        lonaxis_range=[-180, -60],\n",
    "        lataxis_range=[10, 90]\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=1000\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "769402cb-c5e4-4911-b854-95dd5539b102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airport_locs['type'] = 'airport'\n",
    "airport_locs['size'] = 0.3\n",
    "station_locs['type'] = 'station'\n",
    "station_locs['size'] = 0.5\n",
    "combined_locs = pd.concat([station_locs, airport_locs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dad510d7-4be4-4e70-ac6d-227bec408b8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(\n",
    "    combined_locs,\n",
    "    lat='lat',\n",
    "    lon='lon',\n",
    "    color='type',\n",
    "    opacity=0.5,\n",
    "    # size=combined_locs['size']/10,\n",
    "    scope='usa',\n",
    "    title='Weather Stations and Airports'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbc96799-a879-48a0-acb0-94d7ef4dc1ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Prophet modeling for time series characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66077d62-a910-4571-94ed-f2fa0faa1bbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get US holidays\n",
    "us_holidays = make_holidays_df(\n",
    "    year_list=[2013 + i for i in range(10)], country='US'\n",
    ")\n",
    "display(us_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f83345a8-cf75-413e-8de6-190bbe273325",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def to_dt(yyyymmdd, hhmm, tz):\n",
    "    \"\"\"\n",
    "    Create UTC timestamp from flights table columns\n",
    "    yyyymmdd = FL_DATE\n",
    "    hhmm = CRS_DEP_TIME\n",
    "    tz = time zone from time zone table\n",
    "\n",
    "    Returns UTC time stamp, (cast to string)\n",
    "    \"\"\"\n",
    "\n",
    "    hhmm = int(hhmm)\n",
    "\n",
    "    yyyy,MM,dd = yyyymmdd.split('-')\n",
    "    yyyy = int(yyyy) # get year\n",
    "    MM = int(MM) # get month\n",
    "    dd = int(dd) # get day\n",
    "\n",
    "    hh = hhmm//100 # get hour\n",
    "    mm = hhmm%100 # get minute\n",
    "    if hh == 24:\n",
    "        hh = 0\n",
    "        shift = True\n",
    "    else:\n",
    "        shift = False\n",
    "\n",
    "    # create datetime variable for departure\n",
    "    dt_dep = datetime(yyyy,MM,dd,hh,mm)\n",
    "    if shift:\n",
    "        dt_dep += timedelta(days=1)\n",
    "    # apply local time zone\n",
    "    local = pytz.timezone(tz).localize(dt_dep)\n",
    "\n",
    "    dt_format = \"%Y-%m-%dT%H:%M:%S\"\n",
    "\n",
    "    # return UTC datetime, cast to string\n",
    "    return (local.strftime(dt_format))\n",
    "\n",
    "dt_udf = udf(to_dt, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada23c64-ad82-4ebf-b28e-d2ff49d3d9c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out = df.withColumn('local_dep_datetime', to_timestamp(dt_udf(col(\"FL_DATE\"), col(\"CRS_DEP_TIME\"), col(\"origin_tz\")))).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e4523d-ca56-4976-9cbd-5306aa2ce58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tmp = out.limit(10000).filter(df.ORIGIN.isin(['BOS','ORD'])) \\\n",
    "    .withColumnRenamed(\"DEP_DELAY\",\"y\").withColumnRenamed(\"local_dep_datetime\",\"ds\")\n",
    "display(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1491cc8-806c-4138-b312-f80ccc87e335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# informed by: https://www.databricks.com/blog/2021/04/06/fine-grained-time-series-forecasting-at-scale-with-facebook-prophet-and-apache-spark-updated-for-spark-3.html\n",
    "\n",
    "def forecast_delay(history_pd: pd.DataFrame) -> pd.DataFrame: \n",
    "    \n",
    "    model = Prophet(\n",
    "        interval_width=0.9,\n",
    "        growth='linear',\n",
    "        weekly_seasonality=True,\n",
    "        daily_seasonality=True,\n",
    "        yearly_seasonality=True,\n",
    "        # holidays=us_holidays,\n",
    "        # seasonality_mode='multiplicative'\n",
    "    )\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(history_pd)\n",
    "    \n",
    "    # configure predictions\n",
    "    future_pd = model.make_future_dataframe(\n",
    "        periods=24*7, \n",
    "        freq='h',\n",
    "        include_history=False\n",
    "    )\n",
    "    \n",
    "    # make predictions\n",
    "    results_pd = model.predict(future_pd)\n",
    "\n",
    "    # ref date and dow\n",
    "    ref_date = history_pd.ds.iloc[0].date()\n",
    "    ref_dow = history_pd.DAY_OF_WEEK[0]\n",
    "\n",
    "    def get_dow(x,ref_date,dow):\n",
    "        d_days = (x.date() - ref_date).days + dow\n",
    "        d_days = d_days%7\n",
    "        if d_days == 0:\n",
    "            d_days = 7\n",
    "        return d_days\n",
    "\n",
    "    # dateshift\n",
    "    results_pd['dow'] = results_pd.ds.apply(lambda x: get_dow(x,ref_date,ref_dow))\n",
    "\n",
    "    # hour\n",
    "    results_pd['hour'] = results_pd.ds.apply(lambda x: x.hour)\n",
    "\n",
    "    # apply origin\n",
    "    results_pd['ORIGIN'] = history_pd.ORIGIN.iloc[0]\n",
    "\n",
    "    # # get seasonality\n",
    "    # results_pd['seasonality'] = results_pd['weekly'] + results_pd['daily']\n",
    "        \n",
    "    # return predictions\n",
    "    return results_pd[['dow','hour','weekly','daily','ORIGIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7b49dc5-4eb5-471e-8c79-556b3799087b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tmp_out = forecast_delay(tmp.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "856a91b3-c5a6-4c6c-91e5-0a454e496eeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tmp_out_spark = spark.createDataFrame(tmp_out)\n",
    "tmp_out_spark.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e33ffee-6744-4614-a502-36fc336ff434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tmp_out['x'] = tmp_out['dow'] + tmp_out['hour']/24\n",
    "tmp_out.sort_values('x',inplace=True)\n",
    "tmp_out.plot(x='x',y='daily')\n",
    "plt.show()\n",
    "tmp_out.plot(x='x',y='weekly')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fdc3fbb-6cad-437f-ac4d-dc156aaf5913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_max = datetime(2019,2,1)\n",
    "\n",
    "# informed by: https://www.databricks.com/blog/2021/04/06/fine-grained-time-series-forecasting-at-scale-with-facebook-prophet-and-apache-spark-updated-for-spark-3.html\n",
    "\n",
    "results = (\n",
    "    out.filter(df.dep_datetime < train_max) \\\n",
    "    .withColumnRenamed(\"DEP_DELAY\",\"y\").withColumnRenamed(\"local_dep_datetime\",\"ds\")\n",
    "    .groupBy('ORIGIN')\n",
    "          .applyInPandas(forecast_delay, schema=tmp_out_spark.schema)\n",
    "        .withColumn('model_training_date', current_date())\n",
    "        .withColumn('model_training_max_dt', lit(train_max.strftime('%Y-%m-%d')))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e6b7f18-85c0-4a50-a07e-215752e2ca79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d064fa89-c61e-48e3-896c-652ffa3d00a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{folder_path}/interim\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac08f49c-5713-4e70-a02c-2168efffb5e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results.write.parquet(f\"{folder_path}/interim/{dataset}_seasonality_tr{train_max.date()}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "0.06-eil-flights-eda",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
