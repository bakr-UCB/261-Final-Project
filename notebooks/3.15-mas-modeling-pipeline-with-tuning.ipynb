{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa988ec4-230e-49bc-868f-55235d230db0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Modeling Hyperparameter tuning Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "165fe1c6-20c0-4156-8fcd-78eff30c68e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "134d7e1c-a32a-4883-bdfb-ca3a7927701a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c5e9bdd-2536-4ffb-b641-9c87ff506349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Any, Union,Callable\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import timedelta\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics,BinaryClassificationMetrics\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    RandomForestClassifier,\n",
    "    MultilayerPerceptronClassifier\n",
    ")\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "import mlflow\n",
    "from hyperopt import hp, STATUS_OK, fmin, tpe, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9566cd15-dea7-4aea-b01e-ba96f5a79119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load your model training\n",
    "%run /Workspace/Users/m.bakr@berkeley.edu/261-Final-Project/flightdelays/modeling/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40542d5e-46eb-4213-9a16-989eb8ee96a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da6df1ab-7364-416b-8a35-70efe4d364ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Variables and directories\n",
    "data_BASE_DIR = \"dbfs:/mnt/mids-w261/datasets_final_project_2022\"\n",
    "team_BASE_DIR = f\"dbfs:/student-groups/Group_4_1\"\n",
    "spark.sparkContext.setCheckpointDir(f\"{team_BASE_DIR}/checkpoints\")\n",
    "period = \"_1y\" # one of the following values (\"\", \"_3m\", \"_6m\", \"_1y\")\n",
    "k = 5 # cv folds\n",
    "overlap = 0.2 # cv overlap\n",
    "\n",
    "# Datasets\n",
    "df = spark.read.parquet(f\"{team_BASE_DIR}/interim/join_checkpoints/joined{period}_cleaned_engineered_timefeat.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "320be5ab-c3e4-4b6e-b7ed-fc1c2c34f4a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Directory Inspection\n",
    "display(dbutils.fs.ls(f\"{team_BASE_DIR}/interim/join_checkpoints/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bd689be-1e15-4a47-aafd-210212a9ef0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## STEP 1 : Features Selection and Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad3ea8b7-6ebb-41e8-974d-c9b09d34d8e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"ORIGIN\",\n",
    "    \"DEST\",\n",
    "    \"QUARTER\",\n",
    "    \"MONTH\",\n",
    "    \"DAY_OF_MONTH\",\n",
    "    \"DAY_OF_WEEK\"\n",
    "]\n",
    "\n",
    "label = \"outcome\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fd7810e-7526-4df1-b877-354bd1d1c454",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c49d2e95-4584-4a67-982d-7a0cc4ce32e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split_timeseries(\n",
    "    df=df,\n",
    "    time_col=\"sched_depart_utc\",\n",
    "    test_fraction=0.2,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29f9de89-edcc-4539-bb4d-eb5b91167e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, pos_weight = add_class_weights(train_df, label_col=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62304ab2-aed9-4e91-9287-4d5e2920e612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## STEP 3: Time-series CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dda14a23-ed8f-4524-9a6e-39b4159fd7f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Testing Time Series CV function\n",
    "folds = time_series_cv_folds(\n",
    "    train_df,\n",
    "    time_col=\"sched_depart_utc\",\n",
    "    k=k,\n",
    "    overlap=overlap,\n",
    "    blocking=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4de61cf5-1bf9-4ff6-8cda-b263d42b4848",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## STEP : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dd84a9f-b5bf-4675-afbe-815c28481c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def cv_eval(predictions: DataFrame, label_col=\"outcome\", prediction_col=\"prediction\", metric:str=\"F2\"):\n",
    "  \"\"\"\n",
    "  Input: transformed df with prediction and label\n",
    "  Output: desired score \n",
    "  \"\"\"\n",
    "  rdd_preds_m = predictions.select(['prediction', label_col]).rdd\n",
    "  rdd_preds_b = predictions.select('outcome','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['outcome'])))\n",
    "  metrics_m = MulticlassMetrics(rdd_preds_m)\n",
    "  metrics_b = BinaryClassificationMetrics(rdd_preds_b)\n",
    "  if metric == \"F2\":\n",
    "    score = np.round(metrics_m.fMeasure(label=1.0, beta=2.0), 4)\n",
    "  elif metric == \"pr\":\n",
    "    score = metrics_b.areaUnderPR\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f41d7990-598b-4ea5-aff1-09b4c4677a61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def model_tuner(\n",
    "    model_name: str,\n",
    "    model_params: Dict[str, Any],\n",
    "    stages,\n",
    "    folds: List[Tuple[DataFrame, DataFrame]],\n",
    "    mlflow_run_name: str = \"/Users/m.bakr@berkeley.edu/flight_delay_tuning\",\n",
    "    metric: str = \"F2\",\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Union[float, str, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Universal tuning function for PySpark classification models using time-series cross-validation.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): One of ['logreg', 'rf', 'mlp', 'xgb']\n",
    "        model_params (Dict[str, Any]): Parameters to apply to the model\n",
    "        folds (List of (train_df, val_df)): Time-aware CV folds\n",
    "        mlflow_run_name (str): Optional MLflow parent run name\n",
    "        verbose (bool): Whether to log outputs during tuning\n",
    "\n",
    "    Returns:\n",
    "        Dict with best average F2 or pr score, model name, and parameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Model factory\n",
    "    model_factory = {\n",
    "        \"logreg\": LogisticRegression,\n",
    "        \"rf\": RandomForestClassifier,\n",
    "        \"mlp\": MultilayerPerceptronClassifier,\n",
    "        \"xgb\": SparkXGBClassifier\n",
    "    }\n",
    "\n",
    "    assert model_name in model_factory, f\"Unsupported model: {model_name}\"\n",
    "\n",
    "    ModelClass = model_factory[model_name]\n",
    "\n",
    "    # Apply required fields\n",
    "    model = ModelClass(\n",
    "        featuresCol=features,\n",
    "        labelCol=label,\n",
    "        weightCol=\"weight\",  # Handles imbalance\n",
    "        **model_params\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(stages=[model] + stages) \n",
    "\n",
    "    scores = []\n",
    "\n",
    "    with mlflow.start_run(run_name=mlflow_run_name):\n",
    "        for i, (train_df, val_df) in enumerate(folds):\n",
    "            fitted_model = pipeline.fit(train_df)\n",
    "            preds = fitted_model.transform(val_df)\n",
    "            score = cv_eval(preds, metric)\n",
    "            scores.append(score)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"[Fold {i+1}] {metric} Score: {score:.4f}\")\n",
    "\n",
    "            mlflow.log_metric(f\"{metric}_fold_{i+1}\", score)\n",
    "\n",
    "        avg_score = float(np.mean(scores))\n",
    "        mlflow.log_param(\"model\", model_name)\n",
    "        mlflow.log_params(model_params)\n",
    "        mlflow.log_metric(\"avg_{metric}_score\", avg_score)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"âœ… Average {metric} Score: {avg_score:.4f} | Model: {model_name}\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"params\": model_params,\n",
    "        \"avg_f2_score\": avg_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85f2801c-bf0c-44a0-9bed-e2ca4eb7940b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_hyperopt_objective(\n",
    "    model_name: str,\n",
    "    folds: List[Tuple[DataFrame, DataFrame]],\n",
    "    stages: List,\n",
    "    param_space_converter: Callable[[Dict[str, Any]], Dict[str, Any]],\n",
    "    mlflow_experiment_name: str = \"Hyperopt_Universal_Tuning\",\n",
    "    verbose: bool = True\n",
    ") -> Callable[[Dict[str, Any]], Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Creates a Hyperopt-compatible objective function for any PySpark classifier.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): One of 'logreg', 'rf', 'mlp', 'xgb'.\n",
    "        folds (List of (train_df, val_df)): Time-series CV folds.\n",
    "        param_space_converter (Callable): Converts Hyperopt sample into model params.\n",
    "        mlflow_experiment_name (str): MLflow experiment name.\n",
    "        verbose (bool): Logging toggle.\n",
    "\n",
    "    Returns:\n",
    "        Callable that can be passed as fn to hyperopt.fmin()\n",
    "    \"\"\"\n",
    "\n",
    "    def objective(sampled_params: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Convert sampled param space to Spark-friendly params\n",
    "        model_params = param_space_converter(sampled_params)\n",
    "\n",
    "        result = model_tuner(\n",
    "            model_name=model_name,\n",
    "            model_params=model_params,\n",
    "            stages=stages,\n",
    "            folds=folds,\n",
    "            mlflow_run_name=f\"hyperopt_{model_name}\",\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"loss\": -result[\"avg_f2_score\"],  # Minimize negative F2\n",
    "            \"status\": STATUS_OK,\n",
    "            \"params\": result[\"params\"]\n",
    "        }\n",
    "\n",
    "    return objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42387b9d-111d-43a4-b6da-de46968fc2a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c8eb8bc-9cf8-44fc-8e20-8abd5d2400e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Testing Time Series CV function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f33ca572-5259-40f9-8b86-f0fe9b896938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48385f3b-f583-4f25-9f16-cbb6a7da1b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Random Forest Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34627366-ee45-477f-a60e-98eca004b637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define random search param grid\n",
    "param_grid = []\n",
    "for _ in range(10):  # 10 random configs\n",
    "    param_grid.append({\n",
    "        \"numTrees\": random.choice([50, 100, 200]),\n",
    "        \"maxDepth\": random.choice([5, 10, 15]),\n",
    "        \"featureSubsetStrategy\": random.choice([\"auto\", \"sqrt\", \"log2\"])\n",
    "    })\n",
    "\n",
    "# Define other stages\n",
    "stages= []\n",
    "\n",
    "# Run custom tuner\n",
    "best_model, best_params, best_score = model_tuner(\n",
    "    model_class=RandomForestClassifier,\n",
    "    param_grid_list=param_grid,\n",
    "    folds=folds,\n",
    "    experiment_name=\"/Users/m.bakr@berkeley.edu/flight_delay_tuning\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Best F2 Score:\", best_score)\n",
    "print(\"Best Params:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8afb52e8-e579-420e-87b8-90008db2ebeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define Hyperopt search space\n",
    "rf_space = {\n",
    "    \"numTrees\": hp.choice(\"numTrees\", [50, 100, 200]),\n",
    "    \"maxDepth\": hp.quniform(\"maxDepth\", 5, 15, 1),\n",
    "    \"featureSubsetStrategy\": hp.choice(\"featureSubsetStrategy\", [\"auto\", \"sqrt\", \"log2\"])\n",
    "}\n",
    "\n",
    "def rf_param_mapper(sampled: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"numTrees\": int(sampled[\"numTrees\"]),\n",
    "        \"maxDepth\": int(sampled[\"maxDepth\"]),\n",
    "        \"featureSubsetStrategy\": sampled[\"featureSubsetStrategy\"]\n",
    "    }\n",
    "\n",
    "objective = make_hyperopt_objective(\n",
    "    model_name=\"rf\",\n",
    "    folds=folds,\n",
    "    stages=stages,\n",
    "    param_space_converter=rf_param_mapper,\n",
    "    mlflow_experiment_name=\"RF_Hyperopt_Flight_Delay\"\n",
    ")\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=rf_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best Hyperopt Config:\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45077b5f-4cab-49f7-95c1-cdd523abe432",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fada31e0-5f7c-471b-ae24-4f1ecc5ec4ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logreg_space = {\n",
    "    \"regParam\": hp.uniform(\"regParam\", 0.0, 0.5),\n",
    "    \"elasticNetParam\": hp.uniform(\"elasticNetParam\", 0.0, 1.0)\n",
    "}\n",
    "\n",
    "def logreg_param_mapper(sampled):\n",
    "    return {\n",
    "        \"regParam\": sampled[\"regParam\"],\n",
    "        \"elasticNetParam\": sampled[\"elasticNetParam\"],\n",
    "        \"maxIter\": 100\n",
    "    }\n",
    "\n",
    "logreg_obj = make_hyperopt_objective(\n",
    "    model_name=\"logreg\",\n",
    "    folds=folds,\n",
    "    param_space_converter=logreg_param_mapper,\n",
    "    mlflow_experiment_name=\"LogReg_Hyperopt\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_logreg = fmin(\n",
    "    fn=logreg_obj,\n",
    "    space=logreg_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=Trials()\n",
    ")\n",
    "\n",
    "print(\"Best Logistic Regression params:\", best_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69e3bfe3-0e29-49da-bdb2-912292cd9f9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8cbb7cb-fc78-495b-abf8-75bd3fae71eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xgb_space = {\n",
    "    \"eta\": hp.uniform(\"eta\", 0.01, 0.3),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 3, 10, 1),\n",
    "    \"subsample\": hp.uniform(\"subsample\", 0.5, 1.0),\n",
    "    \"colsample_bytree\": hp.uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "    \"num_round\": hp.quniform(\"num_round\", 50, 200, 10)\n",
    "}\n",
    "\n",
    "def xgb_param_mapper(sampled):\n",
    "    return {\n",
    "        \"eta\": sampled[\"eta\"],\n",
    "        \"max_depth\": int(sampled[\"max_depth\"]),\n",
    "        \"subsample\": sampled[\"subsample\"],\n",
    "        \"colsample_bytree\": sampled[\"colsample_bytree\"],\n",
    "        \"num_round\": int(sampled[\"num_round\"]),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"num_workers\": 2,\n",
    "        \"verbosity\": 0\n",
    "    }\n",
    "xgb_obj = make_hyperopt_objective(\n",
    "    model_name=\"xgb\",\n",
    "    folds=folds,\n",
    "    param_space_converter=xgb_param_mapper,\n",
    "    mlflow_experiment_name=\"XGBoost_Hyperopt\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_xgb = fmin(\n",
    "    fn=xgb_obj,\n",
    "    space=xgb_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=Trials()\n",
    ")\n",
    "\n",
    "print(\"Best XGBoost params:\", best_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e730c8e-f4fe-4881-9098-282c1aeffd2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "803abca7-ec4b-4ad3-abff-fd523b2a9025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlp_space = {\n",
    "    \"hidden_layers\": hp.choice(\"hidden_layers\", [[64, 32], [128, 64], [100, 50]]),\n",
    "    \"stepSize\": hp.uniform(\"stepSize\", 0.01, 0.3),\n",
    "    \"maxIter\": hp.choice(\"maxIter\", [100, 200]),\n",
    "    \"blockSize\": hp.choice(\"blockSize\", [64, 128])\n",
    "}\n",
    "\n",
    "def mlp_param_mapper(sampled):\n",
    "    return {\n",
    "        \"layers\": [input_dim] + sampled[\"hidden_layers\"] + [2],\n",
    "        \"stepSize\": sampled[\"stepSize\"],\n",
    "        \"maxIter\": sampled[\"maxIter\"],\n",
    "        \"blockSize\": sampled[\"blockSize\"]\n",
    "    }\n",
    "\n",
    "mlp_obj = make_hyperopt_objective(\n",
    "    model_name=\"mlp\",\n",
    "    folds=folds,\n",
    "    param_space_converter=mlp_param_mapper,\n",
    "    mlflow_experiment_name=\"MLP_Hyperopt\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_mlp = fmin(\n",
    "    fn=mlp_obj,\n",
    "    space=mlp_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=20,\n",
    "    trials=Trials()\n",
    ")\n",
    "\n",
    "print(\"Best MLP params:\", best_mlp)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.15-mas-modeling-pipeline-with-tuning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
