{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e24da7ac-e621-478c-8dd6-209e6a99fb81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5611650-e33e-4d1a-bca2-22c216d6d116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import datetime, timedelta, time\n",
    "from prophet import Prophet\n",
    "from prophet.make_holidays import make_holidays_df\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from prophet.plot import plot_forecast_component\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, StructType, DoubleType, LongType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics,BinaryClassificationMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, when, to_timestamp, lit, udf\n",
    "from pyspark.ml import Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col, to_timestamp, to_date, when\n",
    "from prophet.make_holidays import make_holidays_df\n",
    "from xgboost.spark import SparkXGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1931ec8e-0a0e-4c54-9357-6e64ab859b40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Variables and directories\n",
    "data_BASE_DIR = \"dbfs:/mnt/mids-w261/datasets_final_project_2022\"\n",
    "team_BASE_DIR = f\"dbfs:/student-groups/Group_4_1\"\n",
    "spark.sparkContext.setCheckpointDir(f\"{team_BASE_DIR}/checkpoints\")\n",
    "period = \"\" # one of the following values (\"\", \"_3m\", \"_6m\", \"_1y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "635cbd9a-8613-4e46-8c05-932149510072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Datasets\n",
    "flights = spark.read.parquet(f\"{data_BASE_DIR}/parquet_airlines_data{period}\")\n",
    "weather = spark.read.parquet(f\"{team_BASE_DIR}/interim/weather_{period}_checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a43e5f5a-badf-4c7e-b741-d1817be88aab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Get dataset sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8cdca1c-f313-4685-8c2e-f370d34444e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = flights.count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_columns = len(flights.columns)\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(f\"The flights DataFrame has {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4021f47-9443-4be8-be8d-b21c2622b109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = flights.filter(flights.YEAR < 2020).count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_columns = len(flights.columns)\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(f\"The 5 year flights DataFrame has {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a92881b9-bae5-47ee-94dd-edad6463933d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = weather.count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_columns = len(weather.columns)\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(f\"The weather DataFrame has {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25ec77b4-f1b5-46a3-96e1-0ab349433c54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = weather.filter(weather.YEAR < 2020).count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_columns = len(weather.columns)\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(f\"The 5 year weather DataFrame has {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "017be711-4f43-49b5-8c91-1cbbb4b4c806",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flights = flights.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8331d270-cbe1-4bd8-b028-e77e7967b533",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "keep_me = [\n",
    "    'CARRIER_DELAY',\n",
    "    'WEATHER_DELAY',\n",
    "    'NAS_DELAY',\n",
    "    'SECURITY_DELAY',\n",
    "    'LATE_AIRCRAFT_DELAY',\n",
    "    'DEP_DELAY',\n",
    "    'CANCELLED',\n",
    "    'YEAR'\n",
    "]\n",
    "\n",
    "outcome_info = flights.select(keep_me).toPandas()\n",
    "\n",
    "outcome_info['is_delayed'] = (outcome_info['DEP_DELAY'] >= 15)\n",
    "outcome_info['is_cancelled'] = (outcome_info['CANCELLED'] > 0)\n",
    "outcome_info['outcome'] = outcome_info['is_delayed'] | outcome_info['is_cancelled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7209bb10-0ba0-4470-8d61-1a14c48449b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [np.mean(outcome_info['outcome']), np.mean(np.logical_not(outcome_info['outcome']))]\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "ax.barh([''],data[0], color='black',height=0.25,edgecolor='black',label='Delayed')\n",
    "ax.barh([''],data[1], color='gray',height=0.25,edgecolor='black',left=data[0],label='Not Delayed')\n",
    "ax.set_xlabel('Proportion')\n",
    "ax.set_title('Proportion of delayed flights')\n",
    "ax.set_xlim((0,1))\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(0.5,-0.3),ncol=2)\n",
    "plt.show()\n",
    "\n",
    "reason_cols = [c for c in outcome_info.columns if \"_DELAY\" in c and c not in [\"DIV_ARR_DELAY\",\"DEP_DELAY\"]]\n",
    "# delayed = outcome_info[outcome_info['DEP_DELAY'] > 0][reason_cols].fillna(0)\n",
    "delayed = outcome_info[outcome_info['outcome']][reason_cols].fillna(0)\n",
    "for v in delayed.columns:\n",
    "    data = [np.mean(delayed[v] > 0), np.mean(delayed[v] <= 0)]\n",
    "\n",
    "    fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "    ax.barh([''],data[0], color='black',height=0.25,edgecolor='black',label='Delayed')\n",
    "    ax.barh([''],data[1], color='gray',height=0.25,edgecolor='black',left=data[0],label='Not Delayed')\n",
    "    ax.set_xlabel('Proportion')\n",
    "    reason = ' '.join(v.split('_')[0:]).lower()\n",
    "    ax.set_title(f'Proportion of delayed flights delayed by {reason}')\n",
    "    ax.set_xlim((0,1))\n",
    "    ax.legend(loc='upper center',bbox_to_anchor=(0.5,-0.3),ncol=2)\n",
    "    plt.show()\n",
    "\n",
    "# average delay amount attributed to each reason\n",
    "data = np.sum(delayed, axis=0)\n",
    "data = data.sort_values(ascending=False) / np.sum(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e69df253-824c-41a5-bdfd-2ad760a63645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "for idx,v in enumerate(data.index):\n",
    "    if idx == 0:\n",
    "        ax.barh([''],data[v],edgecolor='black',label=v.replace(\"_\",\" \"))\n",
    "    else:\n",
    "        print(data[delayed.columns[idx-1]])\n",
    "        ax.barh([''],data[v],edgecolor='black',label=v.replace(\"_\",\" \"),left=np.sum(data[data.index[:idx]]))\n",
    "ax.set_xlabel('Proportion')\n",
    "ax.set_title(f'Proportion of total delay minutes by DoT delay categories')\n",
    "ax.set_xlim((0,1))\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(0.5,-0.3),ncol=len(data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40ef6d86-2340-4a28-9905-53be3cce1235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "outcome_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3fff117-a7ae-4b8f-a4b2-bc2a94a6f635",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "np.min(outcome_info.YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32850c3c-d174-419d-b846-d8725164db99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delayed = outcome_info[(outcome_info['outcome']) & (outcome_info.YEAR < 2020)][reason_cols].fillna(0)\n",
    "\n",
    "# average delay amount attributed to each reason\n",
    "data = np.sum(delayed, axis=0)\n",
    "data = data.sort_values(ascending=False) / np.sum(data)\n",
    "data\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,2))\n",
    "for idx,v in enumerate(data.index):\n",
    "    if idx == 0:\n",
    "        ax.barh([''],data[v],edgecolor='black',label=v.replace(\"_\",\" \"))\n",
    "    else:\n",
    "        print(data[delayed.columns[idx-1]])\n",
    "        ax.barh([''],data[v],edgecolor='black',label=v.replace(\"_\",\" \"),left=np.sum(data[data.index[:idx]]))\n",
    "ax.set_xlabel('Proportion')\n",
    "ax.set_title(f'Proportion of total delay minutes by DoT delay categories, 2015-2019')\n",
    "ax.set_xlim((0,1))\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(0.5,-0.3),ncol=len(data))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72b62abc-3b23-4619-a08d-bd0772d3afb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Working with joined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "603cb66a-9d5d-45b2-b37d-cf9775d4e067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.parquet(f\"{team_BASE_DIR}/interim/join_checkpoints/joined_flights_weather{period}_v1.parquet\")\n",
    "df = spark.read.parquet(f\"{team_BASE_DIR}/interim/join_checkpoints/joined_{period}_timefeat_seasfeat_cleaned_pr_v2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c64f1ba0-9a86-4234-8c03-0182f7d9084a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = df.count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_columns = len(df.columns)\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(f\"The joined DataFrame has {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59546a27-569e-4a0c-b1f0-34765884ab7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the number of rows\n",
    "num_rows = df.filter(df.YEAR < 2020).count()\n",
    "\n",
    "# Get the number of columns\n",
    "num_columns = len(df.columns)\n",
    "\n",
    "# Display the size of the DataFrame\n",
    "print(f\"The 5 year joined DataFrame has {num_rows} rows and {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aa8cfe8-bbea-4181-8422-e033368f2808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"dep_date_utc\", to_date(col(\"sched_depart_utc\"))) \\\n",
    "  .withColumn(\"outcome\", (when((col(\"DEP_DELAY\") >= 15) | (col(\"CANCELLED\") == 1), 1).otherwise(0)).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7dbdfc-c203-4575-a30d-ac62d32f8d66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, count, to_date, when\n",
    "\n",
    "# Group by dep_date_utc and calculate the average of DEP_DELAY and outcome\n",
    "avg_delays_df = df.groupBy(\"dep_date_utc\").agg(\n",
    "    avg(col(\"DEP_DELAY\")).alias(\"avg_dep_delay\"),\n",
    "    avg(col(\"outcome\")).alias(\"avg_outcome\"),\n",
    "    count(\"*\").alias(\"count\")\n",
    ")\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "avg_delays_pd = avg_delays_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79227ae-6875-45c2-a3c8-f9acd9e97776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sort avg_delays_pd by avg_dep_delay\n",
    "avg_delays_pd_sorted = avg_delays_pd.sort_values(by='dep_date_utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f6a6fdd-eb00-4da8-bccd-11c4905efacb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot avg_dep_delay vs dep_date_utc\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_delays_pd_sorted['dep_date_utc'], avg_delays_pd_sorted['avg_dep_delay'], linestyle='-')\n",
    "plt.xlabel('Departure Date (UTC)')\n",
    "plt.ylabel('Average Departure Delay')\n",
    "plt.title('Average Departure Delay vs Departure Date (UTC)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83629989-f075-46d6-856e-26a2907ba41f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot avg_dep_delay vs dep_date_utc\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_delays_pd_sorted['dep_date_utc'], avg_delays_pd_sorted['avg_outcome'], linestyle='-')\n",
    "plt.xlabel('Departure Date (UTC)')\n",
    "plt.ylabel('Average Proportion of Flights Delayed or Cancelled')\n",
    "plt.title('Proportion of Flights Disrupted vs Departure Date (UTC)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b93a808-372e-459e-8f74-24c2fe4606ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot avg_dep_delay vs dep_date_utc\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_delays_pd_sorted['dep_date_utc'], avg_delays_pd_sorted['count'], linestyle='-')\n",
    "plt.xlabel('Departure Date (UTC)')\n",
    "plt.ylabel('Number of Flights')\n",
    "plt.title('Daily Flight Count vs Departure Date (UTC)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02c236de-a371-4f54-9e61-5d0f07f90731",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lw = 0.8\n",
    "font_size = 12\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(10, 6))\n",
    "\n",
    "ax[0].plot(avg_delays_pd_sorted['dep_date_utc'], avg_delays_pd_sorted['count'], linestyle='-', linewidth=lw)\n",
    "ax[0].set_xlabel('Departure Date (UTC)', fontsize=font_size)\n",
    "ax[0].set_ylabel('# Flights', fontsize=font_size)\n",
    "ax[0].set_title('Quantifying Flight Disruption')\n",
    "ax[0].grid(True)\n",
    "ax[0].set_xlabel('')\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "ax[1].plot(avg_delays_pd_sorted['dep_date_utc'], avg_delays_pd_sorted['avg_outcome'], linestyle='-', linewidth=lw)\n",
    "ax[1].set_ylabel('Daily Average\\nProportion of\\nFlights Disrupted', fontsize=font_size)\n",
    "ax[1].grid(True)\n",
    "ax[1].set_xlabel('')\n",
    "ax[1].set_xticklabels([])\n",
    "ax[1].tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "ax[2].plot(avg_delays_pd_sorted['dep_date_utc'], avg_delays_pd_sorted['avg_dep_delay'], linestyle='-', linewidth=lw)\n",
    "ax[2].set_ylabel('Daily Average\\nFlight Delay\\n(minutes)', fontsize=font_size)\n",
    "ax[2].grid(True)\n",
    "ax[2].set_xlabel('Departure Date (UTC)', fontsize=font_size)\n",
    "ax[2].tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "plt.xticks(rotation=45, fontsize=font_size)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45390e63-bb35-4fa1-9888-d6cc4b07527c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter the DataFrame for rows where YEAR is less than 2020\n",
    "filtered_df = df.filter(col(\"YEAR\") < 2020)\n",
    "\n",
    "# Group by outcome and count the values\n",
    "outcome_counts = filtered_df.groupBy(\"outcome\").count()\n",
    "\n",
    "# Display the result\n",
    "display(outcome_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c0f1834-cf82-4ae6-9473-49937caa3edc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Seasonality Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a596a60-d110-483b-bd42-69d84fc4afa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fn_wd = f\"wd_seasonality_model_{period}_train.parquet\"\n",
    "fn_yh = f\"yh_seasonality_model_{period}_train.parquet\"\n",
    "\n",
    "model_wd = spark.read.parquet(f\"{team_BASE_DIR}/interim/{fn_wd}\")\n",
    "model_yh = spark.read.parquet(f\"{team_BASE_DIR}/interim/{fn_yh}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1500a2f-fb8d-4dca-8100-cfd9c7058f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airport = 'BOS'\n",
    "seas1 = model_wd.filter(col('ORIGIN') == airport).toPandas()\n",
    "seas2 = model_yh.filter(col('ORIGIN') == airport).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6c7c33e-111e-4b6c-8b76-f22734fd3e04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(8, 6), gridspec_kw={'hspace': 0.6})\n",
    "font_size = 10\n",
    "\n",
    "seas1['x'] = seas1['dow'] + seas1['hour'] / 24\n",
    "seas1.sort_values('x', inplace=True)\n",
    "seas1.plot(x='x', y='daily', ax=ax[0], legend=False)\n",
    "seas1.plot(x='x', y='weekly', ax=ax[1], legend=False)\n",
    "\n",
    "seas2.sort_values(['month', 'dom'], inplace=True)\n",
    "seas2['x'] = range(1, seas2.shape[0] + 1)\n",
    "seas2.sort_values('x', inplace=True)\n",
    "seas2.plot(x='x', y='yearly', ax=ax[2], legend=False)\n",
    "seas2.plot(x='x', y='holidays', ax=ax[3], legend=False)\n",
    "\n",
    "ax[0].set_title(f'{airport} Seasonality Components (minutes)\\nTrained on 2015-2018 Data')\n",
    "ax[0].set_xlabel('Day of week', fontsize=font_size)\n",
    "ax[1].set_xlabel('Day of week', fontsize=font_size)\n",
    "ax[0].set_ylabel('Daily', fontsize=font_size)\n",
    "ax[1].set_ylabel('Weekly', fontsize=font_size)\n",
    "ax[2].set_xlabel('Day of year', fontsize=font_size)\n",
    "ax[3].set_xlabel('Day of year', fontsize=font_size)\n",
    "ax[2].set_ylabel('Yearly', fontsize=font_size)\n",
    "ax[3].set_ylabel('Holiday', fontsize=font_size)\n",
    "\n",
    "for axis in ax:\n",
    "    axis.tick_params(axis='both', which='major', labelsize=font_size)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a72687a-6aff-484b-a4d7-a1833a8c1d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Select the relevant columns and convert to Pandas DataFrame\n",
    "selected_columns = [\"daily\", \"weekly\", \"yearly\",\"holidays\", \"outcome\"]\n",
    "df_pd = df \\\n",
    "    .withColumnRenamed(f\"daily_full\",\"daily\") \\\n",
    "    .withColumnRenamed(f\"weekly_full\",\"weekly\") \\\n",
    "    .withColumnRenamed(f\"yearly_full\",\"yearly\") \\\n",
    "    .withColumnRenamed(f\"holidays_full\",\"holidays\") \\\n",
    "        .select(selected_columns).toPandas()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_pd.corr(method='spearman')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Spearman Correlation Heatmap\\nSeasonality Features, 2015-2019 Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b062d9d-e48c-47b6-ad43-e762c5396184",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select the relevant columns and convert to Pandas DataFrame\n",
    "selected_columns = [\"mean_dep_delay\", \"prop_delayed\", \"outcome\"]\n",
    "df_pd = df.select(selected_columns).toPandas()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_pd.corr(method='spearman')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Spearman Correlation Heatmap\\nLagged Delay Stats Features, 2015-2019 Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79697054-58d9-49dd-9049-96e93821f576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Gap Analysis of Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1624047-51c0-4df5-9772-06ea92798965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out = spark.read.parquet(\"dbfs:/student-groups/Group_4_1/interim/modeling_checkpoints/ensemble.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a789818-5ed0-4dea-bd9e-1d5090bf0f74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out = out.withColumn('HOUR', (col('CRS_DEP_TIME') / 100).cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b5b6c19-2f45-483b-847b-63d47f8075b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f9313a1-d60f-4ea0-8fd0-87c25e149cea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter false negatives\n",
    "false_neg = out.filter((col('avg_prediction') == 0) & (col('outcome') == 1))\n",
    "# Filter false positives\n",
    "false_pos = out.filter((col('avg_prediction') == 1) & (col('outcome') == 0))\n",
    "# Filter true negatives\n",
    "true_neg = out.filter((col('avg_prediction') == 0) & (col('outcome') == 0))\n",
    "# Filter true positives\n",
    "true_pos = out.filter((col('avg_prediction') == 1) & (col('outcome') == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57155f97-54ff-453d-bb0b-2b5f154e3a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "false_negatives_day_df = false_negatives_df.withColumn('DAY', col('FL_DATE').cast('date')).groupBy('DAY').count().withColumnRenamed('count', 'false_negatives')\n",
    "false_positives_day_df = false_positives_df.withColumn('DAY', col('FL_DATE').cast('date')).groupBy('DAY').count().withColumnRenamed('count', 'false_positives')\n",
    "true_negatives_day_df = true_negatives_df.withColumn('DAY', col('FL_DATE').cast('date')).groupBy('DAY').count().withColumnRenamed('count', 'true_negatives')\n",
    "true_positives_day_df = true_positives_df.withColumn('DAY', col('FL_DATE').cast('date')).groupBy('DAY').count().withColumnRenamed('count', 'true_positives')\n",
    "\n",
    "# Join dataframes on DAY\n",
    "time_series_day_df = false_negatives_day_df.join(false_positives_day_df, 'DAY', 'outer') \\\n",
    "                                           .join(true_negatives_day_df, 'DAY', 'outer') \\\n",
    "                                           .join(true_positives_day_df, 'DAY', 'outer') \\\n",
    "                                           .orderBy('DAY')\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting\n",
    "time_series_day_pd = time_series_day_df.toPandas()\n",
    "\n",
    "\n",
    "\n",
    "# Plot time series\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(time_series_day_pd['DAY'], time_series_day_pd['false_negatives'], label='False Negatives', color='darkblue')\n",
    "plt.plot(time_series_day_pd['DAY'], time_series_day_pd['false_positives'], label='False Positives', color='darkred')\n",
    "# plt.plot(time_series_day_pd['DAY'], time_series_day_pd['true_negatives'], label='True Negatives')\n",
    "# plt.plot(time_series_day_pd['DAY'], time_series_day_pd['true_positives'], label='True Positives')\n",
    "\n",
    "# Formatting\n",
    "plt.title('Incorrect Predictions by Day and Type')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Count of Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Set x-axis major ticks to every month\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=15))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%b-%Y'))  # Format: 01-Jan-2025\n",
    "\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()       # Avoid label cutoff\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9585fa02-95b7-4597-a928-99261122ad0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "false_neg_airport = false_neg.groupBy('ORIGIN').count().withColumnRenamed('count', 'false_negatives')\n",
    "false_pos_airport = false_pos.groupBy('ORIGIN').count().withColumnRenamed('count', 'false_positives')\n",
    "true_neg_airport = true_neg.groupBy('ORIGIN').count().withColumnRenamed('count', 'true_negatives')\n",
    "true_pos_airport = true_pos.groupBy('ORIGIN').count().withColumnRenamed('count', 'true_positives')\n",
    "\n",
    "airport_df = false_neg_airport.join(false_pos_airport, 'ORIGIN', 'outer') \\\n",
    "                                   .join(true_neg_airport, 'ORIGIN', 'outer') \\\n",
    "                                   .join(true_pos_airport, 'ORIGIN', 'outer') \\\n",
    "                                   .orderBy('ORIGIN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2afd82c2-5956-4da3-92c9-95e3c2e8d0fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame for plotting\n",
    "airport_pd = airport_df.toPandas()\n",
    "\n",
    "airport_pd_selected = airport_pd[['false_negatives', 'false_positives', 'true_negatives', 'true_positives']]\n",
    "\n",
    "# Calculate the sum across rows\n",
    "row_sums = airport_pd_selected.sum(axis=1)\n",
    "\n",
    "airport_pd = airport_pd[row_sums > 5000]\n",
    "\n",
    "# Scale the rows by the sum across rows\n",
    "airport_pd[['false_negatives', 'false_positives', 'true_negatives', 'true_positives']] = airport_pd[['false_negatives', 'false_positives', 'true_negatives', 'true_positives']].div(row_sums, axis=0)\n",
    "\n",
    "display(airport_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2de6b48-4e39-4256-8186-9d055d402c93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sort by false_negatives\n",
    "airport_pd_sorted = airport_pd.sort_values(by='false_negatives', ascending=False)\n",
    "\n",
    "display(airport_pd_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dfe4c5c-1faa-4e71-afe9-b185d3aff15b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add delay_rate column\n",
    "airport_pd_sorted['delay_rate'] = airport_pd_sorted['true_positives'] + airport_pd_sorted['false_negatives']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65b881ed-df9b-40b7-9614-3a194edffac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Add delay_rate column\n",
    "airport_pd_sorted['delay_rate'] = airport_pd_sorted['true_positives'] + airport_pd_sorted['false_negatives']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(y='false_negatives', x='delay_rate', data=airport_pd_sorted, alpha=0.7)\n",
    "\n",
    "# Fit linear regression model\n",
    "sns.regplot(y='false_negatives', x='delay_rate', data=airport_pd_sorted, scatter=False, color='red')\n",
    "\n",
    "plt.title('False Negative Rate vs Delay Rate, by Airport')\n",
    "plt.ylabel('False Negative Rate')\n",
    "plt.xlabel('Delay Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d40935f-2cb3-4bea-9b3e-8e868aac3a96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Add delay_rate column\n",
    "airport_pd_sorted['delay_rate'] = airport_pd_sorted['true_positives'] + airport_pd_sorted['false_negatives']\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(y='false_positives', x='delay_rate', data=airport_pd_sorted, alpha=0.7)\n",
    "\n",
    "# Fit linear regression model\n",
    "sns.regplot(y='false_positives', x='delay_rate', data=airport_pd_sorted, scatter=False, color='red')\n",
    "\n",
    "plt.title('False Positive Rate vs Delay Rate, by Airport')\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('Delay Rate')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9cd07030-219d-4795-a800-91fe42407b8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Airport Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14905241-84ef-48fd-b8f2-02f5b00b4739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "false_neg_airport = false_neg.groupBy('origin_type').count().withColumnRenamed('count', 'false_negatives')\n",
    "false_pos_airport = false_pos.groupBy('origin_type').count().withColumnRenamed('count', 'false_positives')\n",
    "true_neg_airport = true_neg.groupBy('origin_type').count().withColumnRenamed('count', 'true_negatives')\n",
    "true_pos_airport = true_pos.groupBy('origin_type').count().withColumnRenamed('count', 'true_positives')\n",
    "\n",
    "airport_df = false_neg_airport.join(false_pos_airport, 'origin_type', 'outer') \\\n",
    "                                   .join(true_neg_airport, 'origin_type', 'outer') \\\n",
    "                                   .join(true_pos_airport, 'origin_type', 'outer') \\\n",
    "                                   .orderBy('origin_type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65188dbf-d9cc-4289-83ca-dbdef0e4bd6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airport_pd = airport_df.toPandas()\n",
    "display(airport_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2713e33-35d0-4ad0-8e39-6797d57289c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "airport_pd_selected = airport_pd[['false_negatives', 'false_positives', 'true_negatives', 'true_positives']]\n",
    "\n",
    "# Calculate the sum across rows\n",
    "row_sums = airport_pd_selected.sum(axis=1)\n",
    "\n",
    "# Scale the rows by the sum across rows\n",
    "airport_pd[['false_negatives', 'false_positives', 'true_negatives', 'true_positives']] = airport_pd[['false_negatives', 'false_positives', 'true_negatives', 'true_positives']].div(row_sums, axis=0)\n",
    "\n",
    "display(airport_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61abe5f3-6ca2-4c41-bf2d-b0218fcf8717",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "false_negatives_hour_df = false_neg.groupBy('HOUR').count().withColumnRenamed('count', 'false_negatives')\n",
    "false_positives_hour_df = false_pos.groupBy('HOUR').count().withColumnRenamed('count', 'false_positives')\n",
    "true_negatives_hour_df = true_neg.groupBy('HOUR').count().withColumnRenamed('count', 'true_negatives')\n",
    "true_positives_hour_df = true_pos.groupBy('HOUR').count().withColumnRenamed('count', 'true_positives')\n",
    "\n",
    "# Join dataframes on DAY\n",
    "time_series_hour_df = false_negatives_hour_df.join(false_positives_hour_df, 'HOUR', 'outer') \\\n",
    "                                           .join(true_negatives_hour_df, 'HOUR', 'outer') \\\n",
    "                                           .join(true_positives_hour_df, 'HOUR', 'outer') \\\n",
    "                                           .orderBy('HOUR')\n",
    "\n",
    "# Convert to Pandas DataFrame for plotting\n",
    "time_series_day_pd = time_series_hour_df.toPandas()\n",
    "\n",
    "\n",
    "\n",
    "# Plot time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_series_day_pd['HOUR'], time_series_day_pd['false_negatives'], label='False Negatives', color='darkblue')\n",
    "plt.plot(time_series_day_pd['HOUR'], time_series_day_pd['false_positives'], label='False Positives', color='darkred')\n",
    "plt.plot(time_series_day_pd['HOUR'], \\\n",
    "    time_series_day_pd['false_positives'] + time_series_day_pd['false_negatives'] + time_series_day_pd['true_positives'] + time_series_day_pd['true_negatives'], \\\n",
    "        label='Total Count', color='darkgreen')\n",
    "\n",
    "# Formatting\n",
    "plt.title('Incorrect Predictions by Hour and Type')\n",
    "plt.xlabel('Hour of Day (Local Time)')\n",
    "plt.ylabel('Count of Predictions')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.tight_layout()       # Avoid label cutoff\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bab482b-308a-4e93-a9d5-eeb572092898",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out = out.withColumn('is_false_neg',(col('avg_prediction') == 0) & (col('outcome') == 1)) \\\n",
    "         .withColumn('is_false_pos',(col('avg_prediction') == 1) & (col('outcome') == 0)) \\\n",
    "             .withColumn('is_true_neg',(col('avg_prediction') == 0) & (col('outcome') == 0)) \\\n",
    "                 .withColumn('is_true_pos',(col('avg_prediction') == 1) & (col('outcome') == 1))\n",
    "\n",
    "weather_cols = [col for col in out.columns if \"origin_Hourly\" in col]\n",
    "remove_me = [\"origin_HourlyPresentWeatherType\",\"origin_HourlySkyConditions\",\"origin_HourlyWindDirection\"]\n",
    "num_weather_cols = [c for c in weather_cols if c not in remove_me]\n",
    "for column in num_weather_cols:\n",
    "    out = out.withColumn(column, col(column).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e888b8f3-6811-4f93-be91-e3b62058218e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select only the numerical weather columns\n",
    "weather_data = out.select(num_weather_cols+[\"is_false_neg\",\"is_false_pos\"]).toPandas()\n",
    "\n",
    "# Calculate the Spearman correlation matrix\n",
    "correlation_matrix = weather_data.corr(method='spearman')\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Spearman Correlation Heatmap of Weather Columns and Misclassification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7edcf8e-39ed-4b10-9f77-580637a6e8ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Feature Family Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56afd7b7-9a61-4ebe-a9d3-14f30b6fda79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/823be72d395a46a4a6bee7ed2d35a7fe/rf_model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.15-eil-figures",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
