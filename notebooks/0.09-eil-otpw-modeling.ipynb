{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "160ee997-ffbe-40b0-b7de-a8edc810b265",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark.sql.functions as F\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, StructType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import numpy as np\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, when, to_timestamp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baed10ae-b6b0-472a-94b4-d3f802035c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"dbfs:/student-groups/Group_4_1\"\n",
    "dataset = \"OTPW_3M_2015\"\n",
    "df = spark.read.parquet(f\"{folder_path}/interim/{dataset}_clean.parquet\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7875699f-2bf2-42f5-b427-b29b9f25ae14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "# FOR FULL YEAR DATASET, TEST DATA IS OCT THROUGH DEC\n",
    "df_train = df.filter(f.col(\"dep_datetime\") < \"2015-03-01\")\n",
    "df_test = df.filter(f.col(\"dep_datetime\") >= \"2015-03-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41832ca6-a21e-47d1-bd81-39edb8934e05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CODE IN THIS CELL DERIVED FROM DEMO 11 NOTEBOOK\n",
    "\n",
    "def get_cv_time_limits(df, k=3, blocking=False, dep_utc_varname=\"dep_datetime\", verbose=True):\n",
    "    '''\n",
    "    Get time bins for time-series cross validation\n",
    "    '''\n",
    "    n = df.count()\n",
    "    df = df.withColumn(\"row_id\", f.row_number()\n",
    "            .over(Window.partitionBy().orderBy(dep_utc_varname)))\n",
    "    chunk_size = np.floor(n/(k+1))\n",
    "\n",
    "    idx = np.arange(0,)\n",
    "    idx = np.arange(0,n,chunk_size)\n",
    "    idx[-1] = n-1\n",
    "    idx = [int(i)+1 for i in idx]\n",
    "    \n",
    "    if verbose:\n",
    "        print('')\n",
    "        print(f'Number of validation datapoints for each fold is {chunk_size:,}')\n",
    "        print(\"************************************************************\")\n",
    "\n",
    "    bin_edges = df.filter(f.col(\"row_id\").isin(idx)).select(\"row_id\",dep_utc_varname).toPandas()\n",
    "\n",
    "    out = []\n",
    "    for i in range(k):\n",
    "        # define minimum training time based on cross-validation style\n",
    "        if not blocking:\n",
    "            t_min_train = bin_edges[dep_utc_varname][0]\n",
    "        else:\n",
    "            t_min_train = bin_edges[dep_utc_varname][i]\n",
    "        # define maximum training time\n",
    "        t_max_train = bin_edges[dep_utc_varname][i+1]\n",
    "        # define minimum test time\n",
    "        t_min_test = bin_edges[dep_utc_varname][i+1]\n",
    "        # define maximum test_time\n",
    "        t_max_test = bin_edges[dep_utc_varname][i+2]\n",
    "\n",
    "        out.append({\"train_min\":t_min_train, \"train_max\":t_max_train,\n",
    "                    \"test_min\":t_min_test, \"test_max\":t_max_test})\n",
    "    out = pd.DataFrame(out)\n",
    "        \n",
    "    if verbose:\n",
    "        for i in range(k):\n",
    "            print(f'    TRAIN set for fold {i} goes from {out[\"train_min\"][i]} to {out[\"train_max\"][i]}')\n",
    "            print(f'    TEST set for fold {i} goes from {out[\"test_min\"][i]} to {out[\"test_max\"][i]}')\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16ec5079-73d9-4575-b18d-179bff92ab42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_cutoffs = get_cv_time_limits(df_train, k=3, blocking=True, \n",
    "    dep_utc_varname=\"dep_datetime\", verbose=True)\n",
    "cv_cutoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abe1d41a-b6bc-4d0b-b0c7-68356d21d13b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce99f85-9ca1-47a8-8d06-aac1ed25dcea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# simplistic cleaning\n",
    "df = df.withColumn(\"precip\", col(\"HourlyPrecipitation\").cast(\"double\")) \\\n",
    "    .withColumn(\"wind_speed\", col(\"HourlyWindSpeed\").cast(\"double\")) \\\n",
    "    .withColumn(\"outcome\", (when((col(\"DEP_DELAY\") >= 15) | (col(\"CANCELLED\") == 1), 1).otherwise(0)).cast(\"double\")).fillna({\"precip\":0, \"wind_speed\":0})\n",
    "\n",
    "# cast departure time to timestamp\n",
    "df = df.withColumn(\"dep_datetime\", to_timestamp(col(\"dep_datetime\")))\n",
    "\n",
    "# select relevant vars\n",
    "df = df.select(\"outcome\",\"precip\",\"wind_speed\",\"DEP_TIME_BLK\",\"dep_datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f63a4709-59df-45cd-ba6e-281cbce9664f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "## Create the pipeline Object\n",
    "## Resources: \n",
    "### https://spark.apache.org/docs/latest/ml-pipeline.html\n",
    "### https://www.analyticsvidhya.com/blog/2021/05/a-complete-guide-for-creating-machine-learning-pipelines-using-pyspark-mllib-on-google-colab/\n",
    "############### YOUR CODE HERE #################\n",
    "\n",
    "# very simple model: time of day and simple weather info\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"DEP_TIME_BLK\", outputCol=\"DEP_TIME_BLK_index\")\n",
    "encoder = OneHotEncoder(inputCol=\"DEP_TIME_BLK_index\", outputCol=\"DEP_TIME_BLK_vec\")\n",
    "features = [\"DEP_TIME_BLK_vec\",\"precip\",\"wind_speed\"]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", \\\n",
    "    outputCol=\"features_scaled\",withMean=True)\n",
    "lr = LogisticRegression(featuresCol='features_scaled', \\\n",
    "    labelCol='outcome',maxIter=50)\n",
    "pipeline = Pipeline(stages=[indexer,encoder,assembler,scaler,lr])\n",
    "\n",
    "# ## Train the model\n",
    "# lr_pipeline = pipeline.fit(trainDF)\n",
    "# ## Transform the model\n",
    "# lr_predictions_pipeline = lr_pipeline.transform(heldOutDF)\n",
    "############### YOUR CODE HERE #################\n",
    "\n",
    "# ## Create the evaluator (RUN AS IS)\n",
    "# ## HINT: The MSE here (mse) should match lr_mse (For full points)\n",
    "# eval = RegressionEvaluator(labelCol = \"quality\")\n",
    "# mse = eval.evaluate(lr_predictions_pipeline, {eval.metricName: \"mse\"})\n",
    "# print(\"Linear Regression Model:\")\n",
    "# print(f\"\\t MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3599786c-c94f-40ba-bc73-de7d3c44fabb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "df_train = df.filter(f.col(\"dep_datetime\") < \"2015-03-01\")\n",
    "df_test = df.filter(f.col(\"dep_datetime\") >= \"2015-03-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60a3b64f-fb3c-483b-9266-7b219a8217cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# CODE IN THIS CELL DERIVED FROM DEMO 11 NOTEBOOK\n",
    "\n",
    "def upsample(train_df,verbose=False):\n",
    "  '''Upsamples train_df to balance classes'''\n",
    "  #balance classes in train\n",
    "  delay_count = train_df.filter(f.col(\"outcome\") == 1).count()\n",
    "  non_delay_count = train_df.filter(f.col(\"outcome\") == 0).count()\n",
    "\n",
    "  total = delay_count + non_delay_count\n",
    "  keep_percent = non_delay_count / delay_count\n",
    "\n",
    "  train_delay = train_df.filter(f.col('outcome') == 0)\n",
    "  train_non_delay = train_df.filter(f.col('outcome') == 1).sample(withReplacement=True, fraction=keep_percent,seed=42)\n",
    "  train_upsampled = train_delay.union(train_non_delay)\n",
    "  return train_upsampled\n",
    "\n",
    "\n",
    "def downsample(train_df,verbose=False):\n",
    "  '''Downsamples train_df to balance classes'''\n",
    "  #balance classes in train\n",
    "  delay_count = train_df.filter(f.col(\"outcome\") == 1).count()\n",
    "  non_delay_count = train_df.filter(f.col(\"outcome\") == 0).count()\n",
    "\n",
    "  total = delay_count + non_delay_count\n",
    "  keep_percent = delay_count / non_delay_count\n",
    "  \n",
    "  train_delay = train_df.filter(f.col('outcome') == 1)\n",
    "  train_non_delay = train_df.filter(f.col('outcome') == 0).sample(withReplacement=False,fraction=keep_percent,seed=42)\n",
    "  train_downsampled = train_delay.union(train_non_delay)\n",
    "  return train_downsampled\n",
    "\n",
    "def cv_eval(preds):\n",
    "  \"\"\"\n",
    "  Input: transformed df with prediction and label\n",
    "  Output: desired score \n",
    "  \"\"\"\n",
    "  rdd_preds_m = preds.select(['prediction', 'outcome']).rdd\n",
    "  rdd_preds_b = preds.select('outcome','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['outcome'])))\n",
    "  metrics_m = MulticlassMetrics(rdd_preds_m)\n",
    "  metrics_b = BinaryClassificationMetrics(rdd_preds_b)\n",
    "  F2 = np.round(metrics_m.fMeasure(label=1.0, beta=2.0), 4)\n",
    "  pr = metrics_b.areaUnderPR\n",
    "  return F2, pr\n",
    "\n",
    "def timeSeriesSplitCV(dataset, pipeline, k=3, blocking=False, sampling=None, metric='f2', verbose=True):\n",
    "  '''\n",
    "  Perform timSeriesSplit k-fold cross validation \n",
    "  '''\n",
    "  # # Initiate trackers\n",
    "  # best_score = 0\n",
    "  # best_param_vals = None\n",
    "   \n",
    "  df=dataset\n",
    "  n=df.count()\n",
    "  df = df.withColumn(\"row_id\", f.row_number().over(Window.partitionBy().orderBy(\"dep_datetime\")))\n",
    "  chunk_size = int(n/(k+1))\n",
    "  \n",
    "  print('')\n",
    "  print(f'Number of validation datapoints for each fold is {chunk_size:,}')\n",
    "  print(\"************************************************************\")\n",
    "  \n",
    "  # Track score\n",
    "  scores=[]\n",
    "  \n",
    "  # Start k-fold\n",
    "  for i in range(k):\n",
    "    \n",
    "    # If TimeseriesSplit \n",
    "    if not blocking:\n",
    "      train_df = df.filter(f.col('row_id') <= chunk_size * (i+1)).cache()\n",
    "    # If BlockingSplit\n",
    "    else:\n",
    "      train_df = df.filter((f.col('row_id') > chunk_size * i)&(f.col('row_id') <= chunk_size * (i+1))).cache()\n",
    "      \n",
    "    # Create dev set\n",
    "    dev_df = df.filter((f.col('row_id') > chunk_size * (i+1))&(f.col('row_id') <= chunk_size * (i+2))).cache()  \n",
    "\n",
    "    # Apply sampling on train if selected\n",
    "    if sampling=='down':\n",
    "      train_df = downsample(train_df)\n",
    "      train_df = train_df.cache()\n",
    "    elif sampling=='up':\n",
    "      train_df = upsample(train_df)\n",
    "      train_df = train_df.cache()\n",
    "    # elif sampling=='weights':\n",
    "    #   train_df = add_class_weights(train_df).cache()\n",
    "      \n",
    "    #print info on train and dev set for this fold\n",
    "    if verbose:\n",
    "      print('    TRAIN set for fold {} goes from {} to {}, count is {:,} flights ({})'.format((i+1), \n",
    "                                                                                      train_df.agg({'dep_datetime':'min'}).collect()[0][0],\n",
    "                                                                                      train_df.agg({'dep_datetime':'max'}).collect()[0][0],\n",
    "                                                                                      train_df.count(),\n",
    "                                                                                      sampling + '-sampled' if sampling else 'no sampling'))\n",
    "      print('    DEV set for fold {} goes from {} to {}, count is {:,} flights'.format((i+1), \n",
    "                                                                                      dev_df.agg({'dep_datetime':'min'}).collect()[0][0],\n",
    "                                                                                      dev_df.agg({'dep_datetime':'max'}).collect()[0][0],\n",
    "                                                                                      dev_df.count()))      \n",
    "    # Fit params on the model\n",
    "    model = pipeline.fit(train_df)\n",
    "    dev_pred = model.transform(dev_df)\n",
    "    if metric=='f2':\n",
    "      score = cv_eval(dev_pred)[0]\n",
    "    elif metric=='pr':\n",
    "      score = cv_eval(dev_pred)[1]\n",
    "    scores.append(score)\n",
    "    print(f'    Number of training datapoints for fold number {i+1} is {train_df.count():,} with a {metric} score of {score:.2f}') \n",
    "    print('------------------------------------------------------------')\n",
    "  \n",
    "  # Take average of all scores\n",
    "  avg_score = np.average(scores)    \n",
    "  print(f'Average {metric} score across all folds is {avg_score:.2f}')\n",
    "  print(\"************************************************************\")\n",
    "\n",
    "  # # Train on full df\n",
    "  # print('Training on full train dataset, and validating on dev dataset with best parameters from CV:')\n",
    "  # print(best_parameters)\n",
    "    \n",
    "  # if verbose:\n",
    "  #   print('    TRAIN set for best parameter fitted model goes from {} to {}, count is {:,} flights ({})'.format(train_df.agg({'dep_datetime':'min'}).collect()[0][0],\n",
    "  #                                                                                                    train_df.agg({'dep_datetime':'max'}).collect()[0][0],\n",
    "  #                                                                                                    train_df.count(),\n",
    "  #                                                                                                    sampling + '-sampled' if sampling else 'no sampling'))\n",
    "  return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f37b63b8-f01a-4367-9057-8752b38c21e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "score = timeSeriesSplitCV(df_train, pipeline, k=3, blocking=False, sampling=None, metric='f2', verbose=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "0.09-eil-otpw-modeling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
