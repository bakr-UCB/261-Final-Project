{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6548a44-4b32-4cba-aa16-a2e4024f71c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import datetime, timedelta, time\n",
    "from prophet import Prophet\n",
    "from prophet.make_holidays import make_holidays_df\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from prophet.plot import plot_forecast_component\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, StructType, DoubleType, LongType\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer, OneHotEncoder, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics,BinaryClassificationMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, when, to_timestamp, lit, udf\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f2cdbe1-a1ca-4a92-9a45-965de7342f91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "team_BASE_DIR = f\"dbfs:/student-groups/Group_4_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08fab44b-6e34-4ef5-a27a-b80e5fe7edf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(f\"{team_BASE_DIR}/modeling_checkpoints\")\n",
    "df=spark.read.parquet(f\"{team_BASE_DIR}/interim/join_checkpoints/joined_1y_cleaned_engineered.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23bb90fd-093b-46d9-9d5e-b3fe2d3a6e43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# data time period\n",
    "period = \"1y\" # on of the following values (\"\", \"3m\", \"6m\", \"1y\")\n",
    "\n",
    "# number of cross-validation folds\n",
    "k = 5\n",
    "overlap = 0.2\n",
    "\n",
    "\n",
    "# compute seasonality?\n",
    "# (False if you've already saved out seasonality models for a given CV split setup) #using false since erica already computed\n",
    "compute_seasonality = False\n",
    "\n",
    "# define train/test split date\n",
    "min_test_dt = \"2019-10-01\"\n",
    "\n",
    "# define what departure time variable is called\n",
    "dep_utc_varname = \"sched_depart_utc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5372527-7aee-4295-9168-f38ae6d079cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumns(\n",
    "    {\n",
    "        \"dep_hour_utc\": \n",
    "            F.hour(col(dep_utc_varname)),\n",
    "        \"outcome\":  \n",
    "            (F.when((col(\"DEP_DELAY\") >= 15) | (col(\"CANCELLED\") == 1), 1).otherwise(0)).cast(\"double\")\n",
    "            }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f568068-9399-49c9-ae5a-40fc8e878a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "\n",
    "df_train = df.filter(F.col(dep_utc_varname) < min_test_dt)\n",
    "df_train.cache()\n",
    "df_test = df.filter(F.col(dep_utc_varname) >= min_test_dt)\n",
    "df_test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebc9a2b2-eeab-49dc-98a6-ca6e6bfe4be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_seasonality_data(df, fold, k):\n",
    "  \"\"\"\n",
    "  Look up seasonlaity features from saved seasonality model.\n",
    "  \"\"\"\n",
    "  if fold == 'full':\n",
    "      fn_model = f\"seasonality_model_{period}_train.parquet\"\n",
    "  else:\n",
    "      fn_model = f\"seasonality_model_{period}_cv{fold}of{k}_overlap{overlap}.parquet\"\n",
    "  model = spark.read.parquet(f\"{team_BASE_DIR}/interim/{fn_model}\")\n",
    "\n",
    "  joined_df = df.join(model, \n",
    "                    (df[\"ORIGIN\"] == model[\"ORIGIN\"]) & \n",
    "                    (df[\"DAY_OF_WEEK\"] == model[\"dow\"]) & \n",
    "                    (df[\"dep_hour_utc\"] == model[\"hour\"]),\n",
    "                    how=\"left\").drop(model[\"ORIGIN\"])\n",
    "  \n",
    "  return joined_df\n",
    "\n",
    "\n",
    "# CODE BELOW DERIVED FROM DEMO 11 NOTEBOOK\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "\n",
    "def upsample(train_df,verbose=False):\n",
    "  '''Upsamples train_df to balance classes'''\n",
    "  #balance classes in train\n",
    "  delay_count = train_df.filter(f.col(\"outcome\") == 1).count()\n",
    "  non_delay_count = train_df.filter(f.col(\"outcome\") == 0).count()\n",
    "\n",
    "  total = delay_count + non_delay_count\n",
    "  keep_percent = non_delay_count / delay_count\n",
    "\n",
    "  train_delay = train_df.filter(f.col('outcome') == 0)\n",
    "  train_non_delay = train_df.filter(f.col('outcome') == 1).sample(withReplacement=True, fraction=keep_percent,seed=42)\n",
    "  train_upsampled = train_delay.union(train_non_delay)\n",
    "  return train_upsampled\n",
    "\n",
    "\n",
    "def downsample(train_df,verbose=False):\n",
    "  '''Downsamples train_df to balance classes'''\n",
    "  #balance classes in train\n",
    "  delay_count = train_df.filter(f.col(\"outcome\") == 1).count()\n",
    "  non_delay_count = train_df.filter(f.col(\"outcome\") == 0).count()\n",
    "\n",
    "  total = delay_count + non_delay_count\n",
    "  keep_percent = delay_count / non_delay_count\n",
    "  \n",
    "  train_delay = train_df.filter(f.col('outcome') == 1)\n",
    "  train_non_delay = train_df.filter(f.col('outcome') == 0).sample(withReplacement=False,fraction=keep_percent,seed=42)\n",
    "  train_downsampled = train_delay.union(train_non_delay)\n",
    "  return train_downsampled\n",
    "\n",
    "def cv_eval(preds):\n",
    "  \"\"\"\n",
    "  Input: transformed df with prediction and label\n",
    "  Output: desired score \n",
    "  \"\"\"\n",
    "  rdd_preds_m = preds.select(['prediction', 'outcome']).rdd\n",
    "  rdd_preds_b = preds.select('outcome','probability').rdd.map(lambda row: (float(row['probability'][1]), float(row['outcome'])))\n",
    "  metrics_m = MulticlassMetrics(rdd_preds_m)\n",
    "  metrics_b = BinaryClassificationMetrics(rdd_preds_b)\n",
    "  F2 = np.round(metrics_m.fMeasure(label=1.0, beta=2.0), 4)\n",
    "  pr = metrics_b.areaUnderPR\n",
    "  return F2, pr\n",
    "\n",
    "def timeSeriesSplitCV(df, pipeline, cv_info, sampling=None, metric='f2', verbose=True, dep_utc_varname=dep_utc_varname):\n",
    "  '''\n",
    "  Perform time series split k-fold cross validation \n",
    "  '''\n",
    "\n",
    "  k = len(cv_info)\n",
    "  \n",
    "  # Track score\n",
    "  scores=[]\n",
    "  \n",
    "  # Start k-fold\n",
    "  for i in range(k):\n",
    "    \n",
    "    # Create train set\n",
    "    train_df = df.filter((df[dep_utc_varname] >= cv_info[\"train_min\"][i]) & \\\n",
    "      (df[dep_utc_varname] < cv_info[\"train_max\"][i])).cache()\n",
    "      \n",
    "    # Create dev set\n",
    "    dev_df = df.filter((df[dep_utc_varname] >= cv_info[\"test_min\"][i]) & \\\n",
    "      (df[dep_utc_varname] < cv_info[\"test_max\"][i])).cache() \n",
    "\n",
    "    # Apply sampling on train if selected\n",
    "    if sampling=='down':\n",
    "      train_df = downsample(train_df)\n",
    "      train_df = train_df.cache()\n",
    "    elif sampling=='up':\n",
    "      train_df = upsample(train_df)\n",
    "      train_df = train_df.cache()\n",
    "    # elif sampling=='weights':\n",
    "    #   train_df = add_class_weights(train_df).cache()\n",
    "      \n",
    "    #print info on train and dev set for this fold\n",
    "    if verbose:\n",
    "      print('    TRAIN set for fold {} goes from {} to {}, count is {:,} flights ({})'.format((i+1), \n",
    "                                                                                      train_df.agg({dep_utc_varname:'min'}).collect()[0][0],\n",
    "                                                                                      train_df.agg({dep_utc_varname:'max'}).collect()[0][0],\n",
    "                                                                                      train_df.count(),\n",
    "                                                                                      sampling + '-sampled' if sampling else 'no sampling'))\n",
    "      print('    DEV set for fold {} goes from {} to {}, count is {:,} flights'.format((i+1), \n",
    "                                                                                      dev_df.agg({dep_utc_varname:'min'}).collect()[0][0],\n",
    "                                                                                      dev_df.agg({dep_utc_varname:'max'}).collect()[0][0],\n",
    "                                                                                      dev_df.count()))\n",
    "      \n",
    "    # TODO: remove once feat engineering applied outside\n",
    "    train_df = get_seasonality_data(train_df, i, k)\n",
    "    train_df = train_df.fillna({col:0 for col in ['daily','weekly']})\n",
    "    dev_df = get_seasonality_data(dev_df, i, k)\n",
    "    dev_df = dev_df.fillna({col:0 for col in ['daily','weekly']})\n",
    "\n",
    "    # print(train_df.dtypes)\n",
    "    # print(dev_df.dtypes)\n",
    "        \n",
    "    # Fit params on the model\n",
    "    model = pipeline.fit(train_df)\n",
    "    dev_pred = model.transform(dev_df)\n",
    "    if metric=='f2':\n",
    "      score = cv_eval(dev_pred)[0]\n",
    "    elif metric=='pr':\n",
    "      score = cv_eval(dev_pred)[1]\n",
    "    scores.append(score)\n",
    "    print(f'    Number of training datapoints for fold number {i+1} is {train_df.count():,} with a {metric} score of {score:.2f}') \n",
    "    print('------------------------------------------------------------')\n",
    "  \n",
    "  # Take average of all scores\n",
    "  avg_score = np.average(scores)    \n",
    "  print(f'Average {metric} score across all folds is {avg_score:.2f}')\n",
    "  print(\"************************************************************\")\n",
    "\n",
    "  # # Train on full df\n",
    "  # print('Training on full train dataset, and validating on dev dataset with best parameters from CV:')\n",
    "  # print(best_parameters)\n",
    "    \n",
    "  # if verbose:\n",
    "  #   print('    TRAIN set for best parameter fitted model goes from {} to {}, count is {:,} flights ({})'.format(train_df.agg({dep_utc_varname:'min'}).collect()[0][0],\n",
    "  #                                                                                                    train_df.agg({dep_utc_varname:'max'}).collect()[0][0],\n",
    "  #                                                                                                    train_df.count(),\n",
    "  #                                                                                                    sampling + '-sampled' if sampling else 'no sampling'))\n",
    "  return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96163318-e317-474f-a44d-ab6f53f5bc55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_train_downsampled = downsample(df_train).cache()\n",
    "df_train_seasonal = get_seasonality_data(df_train_downsampled, 'full', k).cache()\n",
    "df_test_seasonal = get_seasonality_data(df_test, 'full', k).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99ec79d0-5da9-4af6-84e4-ee9aec24a774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41786f3a-76d4-4abe-afcd-44fea3884bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3743372-4bd9-4cd0-820a-8189de81903a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_run = 'runs:/5b1caaedee434f1fa84c4b0723099f5e/model'\n",
    "base_model = mlflow.spark.load_model(base_run)\n",
    "base_pred = base_model.transform(df_test_seasonal)\n",
    "# get f2 score\n",
    "base_score = cv_eval(base_pred)[0]\n",
    "print(base_score) #sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "963b791b-6de6-4222-8fa2-c90e372d0bfc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusion_df = base_pred.groupBy('outcome', 'prediction').count().orderBy('outcome', 'prediction')\n",
    "confusion_pd = confusion_df.toPandas()\n",
    "\n",
    "confusion_matrix = confusion_pd.pivot(index='outcome', columns='prediction', values='count').fillna(0)\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Outcome')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3540806-c981-4b37-9e72-ee9282fbfdb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confusion_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6664839-8b42-408e-89c7-3b6311445b71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Added features evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d8e708a-c0ae-4fe6-8519-c7076c7d7124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feats_run = 'runs:/b734b75c14d44c05a96782540f3a4868/model'\n",
    "\n",
    "feats_model = mlflow.spark.load_model(feats_run)\n",
    "feats_pred = feats_model.transform(df_test_seasonal) #df for analysis\n",
    "# get f2 score\n",
    "feats_score = cv_eval(feats_pred)[0]\n",
    "print(feats_score) #sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8038a3c-d1d5-4906-b02f-40e233306468",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Added interactions evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b7a8789-5967-43b4-92fe-27856d04732e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "interacts_run = 'runs:/7da4c9d4d4cd4c418c56268729962bda/model'\n",
    "\n",
    "# Load model\n",
    "interacts_model = mlflow.spark.load_model(interacts_run)\n",
    "\n",
    "# Perform inference via model.transform()\n",
    "interacts_pred = interacts_model.transform(df_test_seasonal)\n",
    "\n",
    "interacts_score = cv_eval(interacts_pred)[0]\n",
    "print(interacts_score) #sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "351f1c5c-b316-4d3b-8ae7-6993372ac4c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Added regularization evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e677602e-6a45-4ea1-9f6b-6c52bf0a9402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "reg_run= 'runs:/d6c4162bb8fd4818bbb714c2c711d628/model'\n",
    "\n",
    "# Load model\n",
    "reg_model = mlflow.spark.load_model(reg_run)\n",
    "\n",
    "# Perform inference via model.transform()\n",
    "reg_preds=reg_model.transform(df_test_seasonal)\n",
    "reg_score = cv_eval(reg_preds)[0]\n",
    "print(reg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb67833a-42df-4ae3-a789-bd57c1cb7308",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_test\n",
    "# df_test_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e39f5fa-c214-4994-8b3b-0e568b250f26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.13-modeling-analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
